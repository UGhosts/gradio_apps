import gradio as gr
from paddlex import create_model
import os
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# --- å…¨å±€OCRå®ä¾‹ ---
ocr_instance = None

# --- æ¨¡å‹ç›®å½•é…ç½® ---
# PaddleX æ¨¡å‹é€šå¸¸ä¿å­˜åœ¨ä¸€ä¸ªç›®å½•ä¸­ï¼Œè¯¥ç›®å½•åŒ…å« model.pdmodel, model.pdiparams, å’Œ model.yml ç­‰æ–‡ä»¶
MODEL_IMAGES_DIR = "/home/software/gradio_apps/model/ele_metric_ocr/PP-OCRv5_mobile_det"
def generate_model_options(base_dir: str) -> dict:
    """
    åŠ¨æ€æ‰«ææŒ‡å®šç›®å½•ï¼Œè‡ªåŠ¨ç”ŸæˆPaddleXçš„æ¨¡å‹é…ç½®å­—å…¸ã€‚
    ä¸€ä¸ªåŒ…å«æ¨¡å‹æ–‡ä»¶çš„å­ç›®å½•ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„ã€å¯åŠ è½½çš„æ¨¡å‹ã€‚
    """
    if not os.path.isdir(base_dir):
        print(f"è­¦å‘Š: æ¨¡å‹æ ¹ç›®å½• '{base_dir}' ä¸å­˜åœ¨ã€‚å°†è¿”å›ç©ºé…ç½®ã€‚")
        return {}
    
    final_options = {}
    for item_name in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item_name)
        # ç”Ÿæˆä¸€ä¸ªå¯¹ç”¨æˆ·æ›´å‹å¥½çš„æ˜¾ç¤ºåç§°
        display_name = item_name.replace('_', ' ').replace('-', ' ')
        # å€¼ç›´æ¥å°±æ˜¯æ¨¡å‹çš„å®Œæ•´è·¯å¾„
        final_options[display_name] = item_path

    if not final_options:
        print(f"è­¦å‘Š: åœ¨ '{base_dir}' ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ PaddleX æ¨¡å‹ã€‚")

    return final_options

# åŠ¨æ€ç”Ÿæˆæ¨¡å‹é€‰é¡¹
MODEL_OPTIONS = generate_model_options(MODEL_IMAGES_DIR)

# --- ç¤ºä¾‹å›¾ç‰‡ç®¡ç† (ä¸å˜) ---
EXAMPLE_IMAGES_DIR = "/home/software/gradio_apps/dataset/ele_metric_ocr"
EXAMPLE_IMAGES = []

def load_example_images():
    """åŠ è½½ç¤ºä¾‹å›¾ç‰‡åˆ—è¡¨"""
    global EXAMPLE_IMAGES
    EXAMPLE_IMAGES = []
    if os.path.exists(EXAMPLE_IMAGES_DIR):
        for filename in sorted(os.listdir(EXAMPLE_IMAGES_DIR)):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                EXAMPLE_IMAGES.append(os.path.join(EXAMPLE_IMAGES_DIR, filename))

load_example_images()

# --- æ–‡ä»¶ç›‘æ§ä¸åº”ç”¨é‡å¯ (ä¸å˜) ---
RESTART_SIGNAL_FILE = ".restart_signal"

def trigger_restart():
    """åˆ›å»ºé‡å¯ä¿¡å·æ–‡ä»¶å¹¶ç»ˆæ­¢å½“å‰åº”ç”¨è¿›ç¨‹ã€‚"""
    print("æ£€æµ‹åˆ°æ–‡ä»¶å˜åŒ–ï¼Œæ­£åœ¨è§¦å‘åº”ç”¨é‡å¯...")
    with open(RESTART_SIGNAL_FILE, "w") as f:
        f.write("restart")
    monitor_manager.stop_all(join_threads=False)
    print("åº”ç”¨è¿›ç¨‹å³å°†é€€å‡º...")
    os._exit(0)

class DirectoryHandler(FileSystemEventHandler):
    def on_created(self, event): trigger_restart()
    def on_deleted(self, event): trigger_restart()
    def on_moved(self, event): trigger_restart()

class MultiDirectoryMonitor:
    """ä¸€ä¸ªå¯ä»¥ç®¡ç†å¤šä¸ªç›®å½•ç›‘æ§ä»»åŠ¡çš„ç±»ã€‚"""
    def __init__(self):
        self._directories_to_watch = set()
        self._observers = []
    def add_directory(self, path: str):
        abs_path = os.path.abspath(path)
        if abs_path not in self._directories_to_watch:
            self._directories_to_watch.add(abs_path)
            print(f"ç›®å½•å·²æ³¨å†Œç›‘æ§: {path}")
    def start_all(self):
        if self._observers: return
        handler = DirectoryHandler()
        for path in self._directories_to_watch:
            os.makedirs(path, exist_ok=True)
            observer = Observer()
            observer.schedule(handler, path, recursive=True)
            self._observers.append(observer)
            observer.start()
        print(f"âœ… å·²å¯åŠ¨å¯¹ {len(self._observers)} ä¸ªç›®å½•çš„ç›‘æ§ã€‚")
    def stop_all(self, join_threads: bool = True):
        for observer in self._observers:
            if observer.is_alive(): observer.stop()
        if join_threads:
            for observer in self._observers: observer.join()
        self._observers = []
        print("âœ… æ‰€æœ‰ç›‘æ§ä»»åŠ¡å·²åœæ­¢ã€‚")

monitor_manager = MultiDirectoryMonitor()

def get_current_examples():
    """è·å–å½“å‰ç¤ºä¾‹å›¾ç‰‡åˆ—è¡¨ï¼ˆæ ¼å¼åŒ–ä¸ºGalleryéœ€è¦çš„æ ¼å¼ï¼‰"""
    print(f"å½“å‰ç¤ºä¾‹å›¾ç‰‡æ•°é‡: {len(EXAMPLE_IMAGES)}")
    return [[path, ""] for path in EXAMPLE_IMAGES] if EXAMPLE_IMAGES else []

def initialize_ocr(model_choice):
    """æ ¹æ®ç”¨æˆ·é€‰æ‹©åˆå§‹åŒ–PaddleX OCRæ¨¡å‹"""
    global ocr_instance
    try:
        if model_choice not in MODEL_OPTIONS:
            return f"âœ— æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_choice}"

        model_path = MODEL_OPTIONS[model_choice]
        if not os.path.isdir(model_path):
            return f"âœ— æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}"
        
        # ä½¿ç”¨ PaddleX åŠ è½½æ¨¡å‹ï¼Œå¯ä»¥æŒ‡å®šä½¿ç”¨GPU
        ocr_instance= create_model(model_name=" PP-OCRv5_mobile_det", model_dir=model_path)
            
        return f"âœ“ æ¨¡å‹ {model_choice} åˆå§‹åŒ–æˆåŠŸ"
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"âœ— æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"

# --- å›¾åƒé¢„å¤„ç† (ä¸å˜) ---
MAX_OCR_IMAGE_SIZE = 1280 

def resize_image_for_ocr(image, max_long_side=MAX_OCR_IMAGE_SIZE):
    """
    å°†å›¾ç‰‡ç­‰æ¯”ä¾‹ç¼©æ”¾åˆ°é€‚åˆOCRå¤„ç†çš„å°ºå¯¸ã€‚
    """
    h, w, _ = image.shape
    if h <= max_long_side and w <= max_long_side:
        return image, 1.0

    if h > w:
        ratio = max_long_side / h
        new_h, new_w = max_long_side, int(w * ratio)
    else:
        ratio = max_long_side / w
        new_w, new_h = max_long_side, int(h * ratio)
        
    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return resized_image, ratio


def draw_ocr_results(image_path, model_choice):
    """
    ä½¿ç”¨ PaddleX è¿›è¡Œ OCR å¹¶ç»˜åˆ¶ç»“æœã€‚
    """
    global ocr_instance
    
    if not os.path.exists(image_path):
        return None, "é”™è¯¯: å›¾ç‰‡æœªæ‰¾åˆ°ã€‚"

    if ocr_instance is None:
        status = initialize_ocr(model_choice)
        if "å¤±è´¥" in status:
            return None, status

    original_image = cv2.imread(image_path)
    if original_image is None:
        return None, "é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶ã€‚"

    try:
        # 1. é¢„å¤„ç†å›¾ç‰‡ç”¨äºOCR
        processed_image, scale_ratio = resize_image_for_ocr(original_image)
        print(f"å›¾ç‰‡å°ºå¯¸å·²ä» {original_image.shape[:2]} é¢„å¤„ç†ä¸º {processed_image.shape[:2]}ï¼Œç¼©æ”¾æ¯”ä¾‹: {scale_ratio:.4f}")
        
        # 2. ä½¿ç”¨ PaddleX æ‰§è¡ŒOCRè¯†åˆ«
        # PaddleX çš„ predict æ–¹æ³•å¯ä»¥ç›´æ¥å¤„ç† numpy æ•°ç»„
        result = ocr_instance.predict(processed_image)
        
        # 3. å‡†å¤‡ç»˜åˆ¶
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/wqy/wqy-microhei.ttc", 25)
        except IOError:
            font = ImageFont.load_default()
        
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
        
        # åœ¨åŸå§‹å°ºå¯¸çš„å›¾ç‰‡ä¸Šè¿›è¡Œç»˜åˆ¶
        pil_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        final_text_label = "æœªæ£€æµ‹åˆ°æ–‡æœ¬"

        if result:
            # 4. ç§»æ¤å¹¶é€‚é…åŸæœ‰çš„ç­›é€‰é€»è¾‘
            # ç¬¬ä¸€æ­¥ï¼šåˆæ­¥ç­›é€‰
            filtered_data = [
                item for item in result
                if len(item['text']) > 3 and (len(item['text']) < 7 or '.' in item['text'])
            ]

            # ç¬¬äºŒæ­¥ï¼šå¦‚æœç»“æœè¶…è¿‡2ä¸ªï¼Œè¿›ä¸€æ­¥ç­›é€‰ä»¥0å¼€å¤´çš„
            if len(filtered_data) > 2:
                zero_start_data = [item for item in filtered_data if item['text'].startswith('0')]
                if zero_start_data:
                    filtered_data = zero_start_data

            # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœä»æœ‰å¤šä¸ªç»“æœï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
            if len(filtered_data) > 1:
                filtered_data = [filtered_data[0]]

            # 5. éå†ç­›é€‰åçš„ç»“æœå¹¶ç»˜åˆ¶gr
            if not filtered_data:
                final_text_label = "æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬"

            for idx, item in enumerate(filtered_data):
                text = item['text'].strip().lstrip('0')
                confidence = item['score']
                
                # å°†æ£€æµ‹æ¡†çš„åæ ‡ä»ç¼©æ”¾åçš„å›¾åƒå°ºå¯¸è¿˜åŸåˆ°åŸå§‹å›¾åƒå°ºå¯¸
                points = np.array(item['polygon'])
                if scale_ratio != 1.0:
                    points = (points / scale_ratio).astype(np.int32)
                
                if not text or confidence < 0.5:
                    continue
                
                color = colors[idx % len(colors)]
                text_label = f'{text}   å¯ä¿¡åº¦: {confidence:.1%}'
                final_text_label = text_label # æ›´æ–°çŠ¶æ€æ–‡æœ¬

                # ç»˜åˆ¶è¾¹æ¡†
                draw.polygon([tuple(p) for p in points], outline=color, width=3)
                
                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯å’Œæ–‡æœ¬
                text_position = (int(points[0][0]), max(0, int(points[0][1]) - 30))
                padding = 5
                try:
                    text_bbox = draw.textbbox(text_position, text_label, font=font)
                    padded_bbox = [
                        text_bbox[0] - padding, text_bbox[1] - padding,
                        text_bbox[2] + padding, text_bbox[3] + padding
                    ]
                    draw.rectangle(padded_bbox, fill=(2, 166, 13))
                except Exception:
                    text_width, text_height = len(text_label) * 12, 25
                    simple_bbox = [
                        text_position[0] - padding, text_position[1] - padding,
                        text_position[0] + text_width + padding, text_position[1] + text_height + padding
                    ]
                    draw.rectangle(simple_bbox, fill=(166, 43, 90))
                
                draw.text(text_position, text_label, fill=(255, 255, 255), font=font)
        
        result_image = np.array(pil_image)
        return result_image, final_text_label
            
    except Exception as e:
        print(f"OCR å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        # è¿”å›åŸå§‹å›¾åƒå’Œé”™è¯¯ä¿¡æ¯
        error_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
        return error_image, f"OCR å¤„ç†å‡ºé”™: {str(e)}"

# --- Gradio ç•Œé¢é€»è¾‘å‡½æ•° (åŸºæœ¬ä¸å˜) ---
def ocr_image(image_path, model_choice):
    """ä¸»å¤„ç†å‡½æ•°"""
    if image_path is None:
        return None, "è¯·å…ˆä¸Šä¼ æˆ–é€‰æ‹©å›¾ç‰‡"
    if not MODEL_OPTIONS:
        return None, "é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ã€‚è¯·æ£€æŸ¥æ¨¡å‹ç›®å½•é…ç½®ã€‚"
    return draw_ocr_results(image_path, model_choice)

def clear_outputs():
    """æ¸…ç©ºæ‰€æœ‰è¾“å‡º"""
    return gr.update(value=None), gr.update(value=None), gr.update(value="")

def change_model(model_choice):
    """åˆ‡æ¢æ¨¡å‹æ—¶çš„å›è°ƒ"""
    global ocr_instance
    ocr_instance = None  # é‡ç½®OCRå®ä¾‹ï¼Œå¼ºåˆ¶åœ¨ä¸‹æ¬¡è¯†åˆ«æ—¶é‡æ–°åˆå§‹åŒ–
    return f"å·²é€‰æ‹©æ¨¡å‹: {model_choice}ï¼Œä¸‹æ¬¡è¯†åˆ«æ—¶å°†è‡ªåŠ¨åŠ è½½"

# health check JS (ä¸å˜)
health_check_js = '''
() => {
    let isConnected = true;
    setInterval(async () => {
        try {
            await fetch('/app_id');
            if (!isConnected) {
                console.log("æˆåŠŸé‡æ–°è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ­£åœ¨åˆ·æ–°é¡µé¢...");
                location.reload();
            }
            isConnected = true;
        } catch (e) {
            if (isConnected) {
                console.log("ä¸æœåŠ¡å™¨çš„è¿æ¥å·²æ–­å¼€ï¼Œç­‰å¾…é‡æ–°è¿æ¥...");
            }
            isConnected = false;
        }
    }, 2000);
}
'''

# --- åˆ›å»º Gradio ç•Œé¢ (ä¸å˜) ---
with gr.Blocks(title="PaddleX æ™ºèƒ½æ–‡å­—è¯†åˆ«", theme=gr.themes.Default(), js=health_check_js) as iface:
    gr.Markdown("""
    # ğŸ” ç”µè¡¨è¯»æ•°OCR (PaddleXç‰ˆ)
    **åŠŸèƒ½ç‰¹ç‚¹ï¼š** æ”¯æŒå¤šç§PaddleXæ¨¡å‹ã€æä¾›ç¤ºä¾‹å›¾ç‰‡ã€å®æ—¶å¯è§†åŒ–è¯†åˆ«ç»“æœã€è‡ªåŠ¨ç›‘æ§ç¤ºä¾‹ä¸æ¨¡å‹ç›®å½•
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ–¼ï¸ ç¤ºä¾‹å›¾ç‰‡")
            initial_examples = get_current_examples()
            example_gallery = gr.Gallery(
                value=initial_examples,
                label="ç‚¹å‡»é€‰æ‹©ç¤ºä¾‹", show_label=False, elem_id="example_gallery",
                columns=4, rows=1, height=200, allow_preview=False
            )
            
            if not initial_examples:
                gr.Markdown("<p style='color:orange;'>*æ²¡æœ‰æ‰¾åˆ°ç¤ºä¾‹å›¾ç‰‡ï¼Œè¯·åœ¨ ./examples/ ç›®å½•ä¸‹æ·»åŠ å›¾ç‰‡æ–‡ä»¶*</p>")
            
            gr.Markdown("### ğŸ¤– æ¨¡å‹é€‰æ‹©")
            model_selector = gr.Dropdown(
                choices=list(MODEL_OPTIONS.keys()),
                value=list(MODEL_OPTIONS.keys())[0] if MODEL_OPTIONS else None,
                label="é€‰æ‹©OCRæ¨¡å‹",
                info="è‡ªåŠ¨æ‰«æå¹¶åŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„PaddleXæ¨¡å‹"
            )
            if not MODEL_OPTIONS:
                gr.Markdown("<p style='color:red;'>*è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„PaddleXæ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ç›®å½•ï¼*</p>")

            with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=True):
                gr.Markdown("""
                **æ“ä½œæ­¥éª¤ï¼š**
                1. ä»ä¸‹æ‹‰èœå•é€‰æ‹©ä¸€ä¸ªOCRæ¨¡å‹ã€‚
                2. ä¸Šä¼ å›¾ç‰‡æˆ–ç‚¹å‡»ä¸€ä¸ªç¤ºä¾‹å›¾ç‰‡ã€‚
                3. ç‚¹å‡»"å¼€å§‹è¯†åˆ«"æŒ‰é’®ã€‚
                4. åœ¨å³ä¾§æŸ¥çœ‹è¯†åˆ«ç»“æœå’Œå¯è§†åŒ–æ ‡æ³¨ã€‚
                """)

        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“¤ ä¸Šä¼ å›¾ç‰‡")
            input_image = gr.Image(type="filepath", label="ä¸Šä¼ å›¾ç‰‡", height=200, sources=['upload'])
            
            with gr.Row():
                submit_btn = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")
            
            gr.Markdown("### ğŸ“‹ è¯†åˆ«ç»“æœ")
            output_image = gr.Image(label="è¯†åˆ«ç»“æœå¯è§†åŒ–", height=600)
            result_status = gr.Textbox(label="è¯†åˆ«ç»“æœ", interactive=False)

    # --- äº‹ä»¶ç»‘å®š (ä¸å˜) ---
    def select_example(evt: gr.SelectData):
        """å½“ç”¨æˆ·ç‚¹å‡»ç¤ºä¾‹å›¾ç‰‡æ—¶è°ƒç”¨"""
        current_examples = get_current_examples()
        path_to_return = None
        if current_examples and evt.index < len(current_examples):
            path_to_return = current_examples[evt.index][0]
        return gr.update(value=path_to_return)

    example_gallery.select(select_example, None, outputs=[input_image])
    
    submit_btn.click(
        fn=ocr_image,
        inputs=[input_image, model_selector],
        outputs=[output_image, result_status]
    )
    
    clear_btn.click(
        fn=clear_outputs,
        outputs=[input_image, output_image, result_status]
    )
    
    model_selector.change(
        fn=change_model,
        inputs=[model_selector]
    )

# --- å¯åŠ¨åº”ç”¨ (ä¸å˜) ---
if __name__ == "__main__":
    os.makedirs(EXAMPLE_IMAGES_DIR, exist_ok=True)
    os.makedirs(MODEL_IMAGES_DIR, exist_ok=True)
    
    # å¯åŠ¨ç›®å½•ç›‘æ§
    monitor_manager.add_directory(EXAMPLE_IMAGES_DIR)
    monitor_manager.add_directory(MODEL_IMAGES_DIR)
    monitor_manager.start_all()
    
    try:
        iface.launch(
            server_name="0.0.0.0",
            server_port=1869,
            share=False,
            debug=True,
            show_error=True
        )
    finally:
        monitor_manager.stop_all(join_threads=True)