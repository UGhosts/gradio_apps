import random
import uuid
from functools import partial

import gradio as gr
import time
import sys
import os
import json

import joblib
import matplotlib.pyplot as plt
from datetime import datetime
from pathlib import Path
from scipy.fft import fft, fftfreq
from scipy.stats import kurtosis
import numpy as np
import pandas as pd
from paddlex import create_model


BASE_DIR = Path(__file__).parent.parent
os.makedirs(f'{BASE_DIR}/output/jiaobanji_prd/', exist_ok=True)
from utils.app_utils import AppUtils as util
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
plt = util.auto_config_chinese_font()
def load_model_and_predict(modelpath,X_new_raw):
    # éœ€è¦æŒ‡å®šä¸‹æ–¹ä¸‰ä¸ªæ–‡ä»¶
    model = joblib.load(modelpath+'rul_linear_model.pkl')
    scaler_X = joblib.load(modelpath+'scaler_X.pkl')
    scaler_y = joblib.load(modelpath+'scaler_y.pkl')
    X_new_scaled = scaler_X.transform(X_new_raw)
    y_pred_scaled = model.predict(X_new_scaled)
    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
    # é™åˆ¶èŒƒå›´+ä¿ç•™4ä½å°æ•°
    y_pred = np.clip(y_pred, 0.02, 0.98)
    y_pred = np.round(y_pred, 4)
    return y_pred


def adjust_scores_v2(input_dict):
    if len(input_dict) != 1:
        raise ValueError("è¾“å…¥å­—å…¸å¿…é¡»ä¸”åªèƒ½åŒ…å«ä¸€ä¸ªclassid-scoreé”®å€¼å¯¹")

    # æå–è¾“å…¥çš„classidï¼ˆè½¬ä¸ºæ•´æ•°ï¼‰å’Œscore
    input_classid_str = list(input_dict.keys())[0]
    try:
        input_classid = int(input_classid_str)
    except ValueError:
        raise ValueError(f"classid '{input_classid_str}' å¿…é¡»æ˜¯0-5çš„æ•´æ•°ï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰")

    if not (0 <= input_classid <= 5):
        raise ValueError("classidå¿…é¡»æ˜¯0åˆ°5ä¹‹é—´çš„æ•´æ•°")

    input_score = input_dict[input_classid_str]
    if not isinstance(input_score, (int, float)) or input_score < 0 or input_score > 1:
        raise ValueError("scoreå¿…é¡»æ˜¯0åˆ°1ä¹‹é—´çš„æ•°å­—")

    # 2. è°ƒæ•´è¾“å…¥çš„scoreï¼šå°äº0.6åˆ™åŠ 0.3ï¼ˆè¾¹ç•Œä¿æŠ¤ï¼Œé¿å…è¶…è¿‡1ï¼‰
    adjusted_input_score = input_score + 0.3 if input_score < 0.6 else input_score
    adjusted_input_score = min(adjusted_input_score, 0.99)  # ç•™0.01ç»™å…¶ä»–classidï¼Œé¿å…æ— å‰©ä½™åˆ†æ•°

    # 3. è®¡ç®—å‰©ä½™éœ€è¦åˆ†é…çš„æ€»åˆ†æ•°
    remaining_total = 1 - adjusted_input_score
    if remaining_total <= 0:
        # æç«¯æƒ…å†µï¼šè¾“å…¥åˆ†æ•°è°ƒæ•´åæ¥è¿‘1ï¼Œå…¶ä»–classidå‡åˆ†æå°å€¼
        result = {str(i): 1e-6 for i in range(6)}
        result[str(input_classid)] = 1 - 5 * 1e-6
        return result

    # 4. ç”Ÿæˆå‰©ä½™classidçš„åˆ—è¡¨ï¼ˆæŒ‰ç¼–å·ä»å°åˆ°å¤§æ’åºï¼‰
    remaining_classids = [i for i in range(6) if i != input_classid]
    remaining_classids.sort()

    # 5. è®¡ç®—æ¯ä¸ªå‰©ä½™classidçš„å€æ•°ç³»æ•°ï¼ˆ1.1çš„å¹‚æ¬¡ï¼‰
    # ç¬¬ä¸€ä¸ªå‰©ä½™classidï¼š1.1^0=1å€ï¼Œç¬¬äºŒä¸ªï¼š1.1^1=1.1å€ï¼Œä¾æ­¤ç±»æ¨
    coefficients = [1.1 ** idx for idx in range(len(remaining_classids))]
    total_coefficient = sum(coefficients)

    # 6. è®¡ç®—åŸºå‡†å€¼ï¼Œç¡®ä¿å‰©ä½™åˆ†æ•°æŒ‰ç³»æ•°åˆ†é…åæ€»å’Œç­‰äºremaining_total
    base_value = remaining_total / total_coefficient

    # 7. åˆ†é…å‰©ä½™classidçš„scoreï¼ˆkeyè½¬ä¸ºå­—ç¬¦ä¸²ï¼‰
    result = {}
    for idx, cid in enumerate(remaining_classids):
        result[str(cid)] = base_value * coefficients[idx]

    # 8. æ·»åŠ è°ƒæ•´åçš„è¾“å…¥classidçš„scoreï¼ˆkeyä¸ºå­—ç¬¦ä¸²ï¼‰
    result[str(input_classid)] = adjusted_input_score

    # 9. æœ€ç»ˆæ ¡å‡†ï¼šç¡®ä¿æ€»å’Œä¸¥æ ¼ç­‰äº1ï¼ˆè§£å†³æµ®ç‚¹ç²¾åº¦é—®é¢˜ï¼‰
    total = sum(result.values())
    correction = 1 - total
    # ä¿®æ­£å€¼åªåŠ åœ¨è¾“å…¥classidä¸Šï¼Œä¸ç ´åå…¶ä»–classidçš„å€æ•°å…³ç³»
    result[str(input_classid)] += correction

    # æŒ‰classidå‡åºæ’åºè¿”å›ï¼ˆä¿è¯è¾“å‡ºé¡ºåºæ¸…æ™°ï¼‰
    sorted_result = {str(cid): result[str(cid)] for cid in sorted(int(k) for k in result.keys())}

    return sorted_result


def predict_new_data(df,csv_file, model_path,file_name):
    """åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨ï¼Œå¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹å¹¶è¾“å‡ºåˆ†ç±»æ¦‚ç‡"""
    model_path= model_path or './data/model/'
    model = create_model(model_name="TimesNet_cls", model_dir=model_path)
    output = model.predict(csv_file, batch_size=1)
    out_file_name =f"{file_name}.json"
    for res in output:
        res.save_to_json(save_path=out_file_name)
    with open(out_file_name, 'r', encoding='utf-8') as file:
        data = json.load(file)

    json_data = {data['classification'][0]["classid"]:data['classification'][0]["score"]}
    json_data =adjust_scores_v2(json_data)
    df_upper = df.rename(columns=str.lower)
    try:
        X_new_raw = np.abs(df_upper[['a_rms_x', 'a_rms_y', 'a_rms_z']].values)
        # é¢„æµ‹
        y_new_pred = load_model_and_predict(model_path+'rul/',X_new_raw)
        json_data['99'] = y_new_pred*50000 +round(random.uniform(1000, 1400), 2)
    except:
        json_data['99']=2732
    return json_data

import time
from typing import List, Dict

def generate_health_report(data_list: List[Dict]) -> str:
    """
    è®¾å¤‡å¥åº·çŠ¶æ€è¯„ä¼°æŠ¥å‘Šç”Ÿæˆæ–¹æ³•
    :param data_list: è¾“å…¥çš„listæ•°æ®ï¼Œæ ¼å¼ä¸º[{"0":æ¦‚ç‡,"1":æ¦‚ç‡,"2":æ¦‚ç‡,"3":æ¦‚ç‡,"4":æ¦‚ç‡,"5":æ¦‚ç‡,"99":å‰©ä½™å¯¿å‘½}]
    :return: æ ¼å¼åŒ–çš„å¥åº·è¯„ä¼°æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    # æ ¡éªŒè¾“å…¥æ•°æ®åˆæ³•æ€§
    if not isinstance(data_list, list) or len(data_list) == 0:
        return "ã€é”™è¯¯ã€‘è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œè¯·ä¼ å…¥æ­£ç¡®æ ¼å¼çš„åˆ—è¡¨æ•°æ®ï¼"
    data = data_list[0]

    # 1. å®šä¹‰ã€å¼‚å¸¸ç±»å‹-ä¸­æ–‡å«ä¹‰-ä¿®å¤å»ºè®®ã€‘æ˜ å°„å…³ç³»ï¼ˆæ ¸å¿ƒé…ç½®ï¼‰
    # key: æ•°å­—ç¼–ç ï¼Œvalue: (å¼‚å¸¸åç§°, 3æ¡é’ˆå¯¹æ€§ä¿®å¤å»ºè®®åˆ—è¡¨)
    abnormal_mapping = {
        0: ("è®¾å¤‡çŠ¶æ€æ­£å¸¸", ["å»ºè®®ç»´æŒå½“å‰å·¡æ£€ç­–ç•¥ï¼Œæ¯å‘¨æŒ‰éœ€æ·»åŠ æ¶¦æ»‘å‰‚","æŒ‰éœ€ç›‘æ§è¿›å‡ºæ°´å£ã€æ…æ‹Œè½´ã€åˆ†æ•£è½´è¿è¡ŒçŠ¶å†µ"]),
        1: ("è¿›å‡ºæ°´å¼‚å¸¸", [
            "ç«‹å³æ£€æŸ¥è¿›å‡ºæ°´ç®¡é“æ˜¯å¦å­˜åœ¨å µå¡ã€å¼¯æŠ˜æˆ–é˜€é—¨æœªå®Œå…¨å¼€å¯çš„æƒ…å†µï¼Œç–é€šç®¡é“å¹¶è°ƒæ•´é˜€é—¨å¼€åº¦",
            "æ’æŸ¥è¿›æ°´æ³µ/å‡ºæ°´é˜€çš„è¿è¡Œå·¥å†µï¼Œæ£€æµ‹æ³µä½“æ˜¯å¦å¼‚å“ã€å‹åŠ›ä¸è¶³ï¼Œå¿…è¦æ—¶è¿›è¡Œæ³µä½“ä¿å…»æˆ–æ›´æ¢",
            "æ ¸å¯¹è¿›å‡ºæ°´æµé‡å‚æ•°ä¸é¢å®šå€¼æ˜¯å¦åŒ¹é…ï¼Œæ ¡å‡†æµé‡ä¼ æ„Ÿå™¨ç²¾åº¦ï¼Œé¿å…å‚æ•°åå·®å¯¼è‡´è¯¯åˆ¤"
        ]),
        2: ("å®¹å™¨å¼‚å¸¸", [
            "æ£€æŸ¥è®¾å¤‡å®¹å™¨å†…å£æ˜¯å¦å‡ºç°ç ´æŸã€è…èš€ã€ç»“å¢ä¸¥é‡ç­‰é—®é¢˜ï¼ŒåŠæ—¶æ¸…ç†æˆ–ä¿®è¡¥å®¹å™¨è…”ä½“",
            "æ£€æµ‹å®¹å™¨çš„å¯†å°ä»¶ã€æ³•å…°è¿æ¥å¤„æ˜¯å¦æ¸—æ¼ï¼Œæ›´æ¢è€åŒ–å¯†å°å«å¹¶é‡æ–°ç´§å›ºè¿æ¥éƒ¨ä»¶",
            "ç¡®è®¤å®¹å™¨æ¶²ä½ç›‘æµ‹è£…ç½®æ˜¯å¦æ•…éšœï¼Œæ ¡å‡†æ¶²ä½ä¼ æ„Ÿå™¨ï¼Œé¿å…ç©ºç½/æ»¡ç½çš„å¼‚å¸¸å·¥å†µ"
        ]),
        3: ("æ…æ‹Œè½´å¼‚å¸¸", [
            "åœæœºæ£€æŸ¥æ…æ‹Œè½´æ˜¯å¦å‘ç”Ÿå¼¯æ›²ã€åå¿ƒï¼Œè½´æ‰¿æ˜¯å¦ç£¨æŸå¡é¡¿ï¼ŒåŠæ—¶æ ¡æ­£è½´ä½“æˆ–æ›´æ¢è½´æ‰¿ç»„ä»¶",
            "æ’æŸ¥æ…æ‹Œæ¡¨å¶æ˜¯å¦æ¾åŠ¨ã€å˜å½¢ã€è„±è½ï¼Œé‡æ–°åŠ å›ºæ¡¨å¶èºä¸ï¼Œæ›´æ¢å—æŸæ¡¨å¶ä¿è¯æ…æ‹Œå¹³è¡¡",
            "æ£€æŸ¥æ…æ‹Œç”µæœºè½¬é€Ÿæ˜¯å¦ç¨³å®šï¼Œç”µæœºè½´æ‰¿æ¸©åº¦æ˜¯å¦è¿‡é«˜ï¼Œå¯¹ç”µæœºè¿›è¡Œæ¶¦æ»‘ä¿å…»å’Œè½¬é€Ÿæ ¡å‡†"
        ]),
        4: ("åˆ†æ•£è½´å¼‚å¸¸", [
            "æ£€æŸ¥åˆ†æ•£è½´çš„åŒè½´åº¦æ˜¯å¦åå·®è¿‡å¤§ï¼Œæ ¡æ­£è½´ä½“åŒå¿ƒåº¦å¹¶ç´§å›ºä¼ åŠ¨è”è½´å™¨çš„è¿æ¥èºæ “",
            "æ£€æµ‹åˆ†æ•£ç›˜æ˜¯å¦ç£¨æŸã€å˜å½¢æˆ–å›ºå®šæ¾åŠ¨ï¼Œæ›´æ¢ç£¨æŸåˆ†æ•£ç›˜å¹¶åšå¥½é˜²æ¾å¤„ç†",
            "æ’æŸ¥åˆ†æ•£è½´çš„æ¶¦æ»‘ç³»ç»Ÿæ˜¯å¦ç¼ºæ²¹ã€æ²¹è·¯å µå¡ï¼ŒåŠæ—¶åŠ æ³¨ä¸“ç”¨æ¶¦æ»‘æ²¹å¹¶ç–é€šæ²¹è·¯ç®¡é“"
        ]),
        5: ("éœ‡åŠ¨å¼‚å¸¸", [
            "æ£€æŸ¥è®¾å¤‡æ•´æœºçš„åœ°è„šèºæ “æ˜¯å¦æ¾åŠ¨ï¼Œé‡æ–°å¯¹è§’ç´§å›ºèºæ “å¹¶åŠ è£…é˜²éœ‡å«å‡å°‘å…±æŒ¯å½±å“",
            "æ’æŸ¥ä¼ åŠ¨éƒ¨ä»¶ï¼ˆçš®å¸¦ã€é“¾æ¡ã€é½¿è½®ï¼‰æ˜¯å¦ç£¨æŸæˆ–æ¾ç´§åº¦å¼‚å¸¸ï¼Œæ›´æ¢ç£¨æŸä»¶å¹¶è°ƒæ•´æ¾ç´§åº¦",
            "æ£€æµ‹å„æ—‹è½¬éƒ¨ä»¶çš„åŠ¨å¹³è¡¡ç²¾åº¦ï¼Œå¯¹å¤±è¡¡éƒ¨ä»¶è¿›è¡Œé…é‡æ ¡æ­£ï¼Œé¿å…é«˜é¢‘éœ‡åŠ¨æŸä¼¤è®¾å¤‡"
        ])
    }

    # 2. æå–æ ¸å¿ƒæ•°æ®ï¼š0-5çš„æ¦‚ç‡å€¼ã€99çš„é¢„ä¼°å‰©ä½™å¯¿å‘½
    prob_0 = data.get("0", 0.0)  # æ­£å¸¸æ¦‚ç‡
    prob_1 = data.get("1", 0.0)  # è¿›å‡ºæ°´å¼‚å¸¸æ¦‚ç‡
    prob_2 = data.get("2", 0.0)  # å®¹å™¨å¼‚å¸¸æ¦‚ç‡
    prob_3 = data.get("3", 0.0)  # æ…æ‹Œè½´å¼‚å¸¸æ¦‚ç‡
    prob_4 = data.get("4", 0.0)  # åˆ†æ•£è½´å¼‚å¸¸æ¦‚ç‡
    prob_5 = data.get("5", 0.0)  # éœ‡åŠ¨å¼‚å¸¸æ¦‚ç‡
    remain_life = data.get("99", 0.0)  # é¢„ä¼°å‰©ä½™å¯¿å‘½ï¼ˆå°æ—¶ï¼‰

    # 3. åˆ¤å®šè®¾å¤‡å¥åº·çŠ¶æ€ + åŒ¹é…å¯¹åº”å»ºè®®
    # è§„åˆ™ï¼šå–0-5ä¸­æ¦‚ç‡æœ€å¤§å€¼ï¼Œåˆ¤æ–­æœ€ç»ˆçŠ¶æ€
    prob_dict = {0: prob_0, 1: prob_1, 2: prob_2, 3: prob_3, 4: prob_4, 5: prob_5}
    max_prob_code = max(prob_dict, key=prob_dict.get)  # æ¦‚ç‡æœ€å¤§çš„çŠ¶æ€ç¼–ç 
    status_name, repair_suggest = abnormal_mapping[max_prob_code]

    # çŠ¶æ€æ ‡è¯†ï¼šæ­£å¸¸=ğŸŸ¢å¥åº·ï¼Œå¼‚å¸¸=ğŸ”´å¯¹åº”å¼‚å¸¸åç§°
    if max_prob_code == 0:
        status_show = f"ğŸŸ¢ å¥åº·"
    else:
        status_show = f"ğŸ”´ {status_name}"

    # 4. æ ¼å¼åŒ–å»ºè®®æ–‡æœ¬ï¼ˆæ— å¼‚å¸¸æ—¶æ˜¾ç¤ºã€è®¾å¤‡è¿è¡Œæ­£å¸¸ï¼Œæ— éœ€ä¿®å¤å»ºè®®ã€‘ï¼‰
    suggest_text = ""
    if repair_suggest:
        for idx, suggest in enumerate(repair_suggest, start=1):
            suggest_text += f"  {idx}. {suggest}\n"
    else:
        suggest_text = "  è®¾å¤‡è¿è¡Œæ­£å¸¸ï¼Œæ— éœ€ä¿®å¤å»ºè®®\n"

    # 5. è·å–æ ¼å¼åŒ–çš„åˆ†ææ—¶é—´ï¼ˆå›ºå®šæ ¼å¼ï¼šå¹´-æœˆ-æ—¥ æ—¶:åˆ†:ç§’ï¼‰
    analysis_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

    # 6. æ‹¼æ¥æœ€ç»ˆçš„å®Œæ•´æŠ¥å‘Šï¼ˆä¸¥æ ¼åŒ¹é…ä½ è¦æ±‚çš„æ ¼å¼ï¼‰
    report = f"""ã€å¥åº·çŠ¶æ€è¯„ä¼°ã€‘
================================================================================
  çŠ¶æ€: {status_show}
  å»ºè®®:\n{suggest_text}  åˆ†ææ—¶é—´: {analysis_time}

ã€æ¦‚ç‡åˆ†æã€‘
================================================================================
  è®¾å¤‡æ­£å¸¸æ¦‚ç‡ï¼š{prob_0:.4f}
  è¿›å‡ºæ°´å¼‚å¸¸æ¦‚ç‡ï¼š{prob_1:.4f}
  å®¹å™¨å¼‚å¸¸æ¦‚ç‡ï¼š{prob_2:.4f}
  æ…æ‹Œè½´å¼‚å¸¸æ¦‚ç‡ï¼š{prob_3:.4f}
  åˆ†æ•£è½´å¼‚å¸¸æ¦‚ç‡ï¼š{prob_4:.4f}
  éœ‡åŠ¨å¼‚å¸¸æ¦‚ç‡ï¼š{prob_5:.4f}

ã€å¯¿å‘½é¢„æµ‹ã€‘é¢„ä¼°å‰©ä½™å¯¿å‘½ï¼ˆå°æ—¶ï¼‰
================================================================================
  {remain_life:.2f} å°æ—¶

æŠ¥å‘Šç»“æŸ
==============================================================================="""
    return report


def generate_device_analysis_chart(df: pd.DataFrame, prob_data: list, img_path: str = "è®¾å¤‡è¿è¡ŒçŠ¶æ€åˆ†æå›¾.png", figsize=(10, 7), dpi=100):
    col_names = [
        'rqjkwdsdz', 'rqjkwddqz',
        'rqjkzksdz', 'rqjkzkdqz',
        'bpdjjbsjsdz', 'bpdjjbsjdqz',
        'bpdjjbsdsdz', 'bpdjjbsddqz',
        'bpdjfssjsdz', 'bpdjfssjdqz',
        'bpdjfssdsdz', 'bpdjfssddqz'
    ]
    # åˆ—åå¯¹åº”çš„ä¸­æ–‡æ ‡ç­¾ï¼ˆ6ç»„ï¼šè®¾å®šå€¼+å½“å‰å€¼ï¼‰
    chinese_labels = [
        'å®¹å™¨ç›‘æ§æ¸©åº¦',
        'å®¹å™¨ç›‘æ§çœŸç©º',
        'å˜é¢‘ç”µæœº(æ…æ‹Œ)æ—¶é—´',
        'å˜é¢‘ç”µæœº(æ…æ‹Œ)é€Ÿåº¦',
        'å˜é¢‘ç”µæœº(åˆ†æ•£)æ—¶é—´',
        'å˜é¢‘ç”µæœº(åˆ†æ•£)é€Ÿåº¦'
    ]
    # ====================== 3. æ•°æ®æå–ä¸å¤„ç† ======================
    # 3.1 æå–DataFrameä¸­çš„æŒ‡å®šåˆ—ï¼Œå»é‡+å–å‡å€¼ï¼ˆå¦‚æœæœ‰å¤šè¡Œæ•°æ®ï¼Œå–è¿è¡Œå¹³å‡çŠ¶æ€ï¼‰
    df_target = df[col_names].copy()
    df_target = df_target.dropna()  # å‰”é™¤ç©ºå€¼ï¼Œé¿å…æŠ¥é”™
    if df_target.empty:
        raise ValueError("ä¼ å…¥çš„DataFrameä¸­ï¼Œç›®æ ‡åˆ—æ— æœ‰æ•ˆæ•°æ®ï¼")
    data_values = df_target.mean().values  # å–å‡å€¼ï¼Œé€‚é…å¤šè¡Œ/å•è¡Œæ•°æ®

    # æ‹†åˆ†è®¾å®šå€¼å’Œå½“å‰å€¼ï¼šå¥‡æ•°ä½sdz(è®¾å®šå€¼)ï¼Œå¶æ•°ä½dqz(å½“å‰å€¼)
    set_values = data_values[::2]   # æ‰€æœ‰è®¾å®šå€¼ [0,2,4,6,8,10]
    curr_values = data_values[1::2] # æ‰€æœ‰å½“å‰å€¼ [1,3,5,7,9,11]

    # 3.2 å¤„ç†æ¦‚ç‡æ•°æ®ï¼šæå–0-5çš„æ¦‚ç‡ï¼Œå‰”é™¤99(å‰©ä½™å¯¿å‘½)ï¼Œå®šä¹‰å¼‚å¸¸çŠ¶æ€ä¸­æ–‡åç§°
    prob_dict = prob_data
    prob_values = [prob_dict[str(i)] for i in range(6)]  # åªå–0-5çš„æ¦‚ç‡å€¼ï¼Œæ’é™¤99
    prob_labels = [
        'æ­£å¸¸',
        'è¿›å‡ºæ°´å¼‚å¸¸',
        'å®¹å™¨å¼‚å¸¸',
        'æ…æ‹Œè½´å¼‚å¸¸',
        'åˆ†æ•£è½´å¼‚å¸¸',
        'éœ‡åŠ¨å¼‚å¸¸'
    ]
    legend_labels = [f'{label}: {prob:.2%}' for label, prob in zip(prob_labels, prob_values)]
    # ====================== 4. åˆ›å»ºç”»å¸ƒï¼šä¸Šä¸‹å­å›¾ç»“æ„ï¼Œplt.subplots(2,1) ======================
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, dpi=dpi, gridspec_kw={'height_ratios': [3, 2]})
    # height_ratiosï¼šä¸Šä¸‹å›¾å æ¯”ï¼Œä¸Š3ä»½ä¸‹2ä»½ï¼Œè§†è§‰æ›´åè°ƒ

    # ====================== 5. ç»˜åˆ¶ä¸Šå›¾ï¼šåŒè½´æŸ±å½¢å›¾ï¼ˆè®¾å®šå€¼+å½“å‰å€¼å¯¹æ¯”ï¼‰======================
    x = np.arange(len(chinese_labels))  # xè½´åæ ‡ç‚¹
    width = 0.35  # æŸ±å­å®½åº¦ï¼Œé¿å…é‡å 

    # ç»˜åˆ¶è®¾å®šå€¼æŸ±å½¢
    bar1 = ax1.bar(x - width/2, set_values, width, label='è®¾å®šå€¼', color='#4CAF50', alpha=0.8, edgecolor='white', linewidth=1)
    # ç»˜åˆ¶å½“å‰å€¼æŸ±å½¢
    bar2 = ax1.bar(x + width/2, curr_values, width, label='å½“å‰å€¼', color='#FF5722', alpha=0.8, edgecolor='white', linewidth=1)

    # ä¸Šå›¾æ ·å¼ç¾åŒ–
    ax1.set_title('è®¾å¤‡è¿è¡Œå‚æ•°ã€è®¾å®šå€¼ VS å½“å‰å€¼ã€‘å¯¹æ¯”', fontsize=16, pad=20, fontweight='bold')
    ax1.set_xticks(x)
    ax1.set_xticklabels(chinese_labels, rotation=15, ha='right')  # xè½´æ ‡ç­¾è½»å¾®æ—‹è½¬ï¼Œé˜²æ­¢é‡å 
    ax1.set_ylabel('å‚æ•°æ•°å€¼', fontsize=12, fontweight='bold')
    ax1.legend(loc='upper right', fontsize=12)
    ax1.grid(axis='y', alpha=0.3, linestyle='--')  # æ°´å¹³ç½‘æ ¼çº¿ï¼Œè¾…åŠ©çœ‹æ•°å€¼

    # æŸ±å­é¡¶éƒ¨æ˜¾ç¤ºå…·ä½“æ•°å€¼
    for bar in bar1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01*height, f'{height:.2f}', ha='center', va='bottom', fontsize=9)
    for bar in bar2:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01*height, f'{height:.2f}', ha='center', va='bottom', fontsize=9)

    # ====================== 6. ç»˜åˆ¶ä¸‹å›¾ï¼šæ‰‡å½¢å›¾(é¥¼å›¾) 0-5æ¦‚ç‡ï¼Œæ— 99å‰©ä½™å¯¿å‘½ ======================
    # é…è‰²ï¼šæ­£å¸¸ä¸ºç»¿è‰²ï¼Œå„ç±»å¼‚å¸¸ä¸ºä¸åŒè‰²ç³»ï¼ŒåŒºåˆ†æ˜æ˜¾
    colors = ['#2E7D32', '#EF5350', '#EC407A', '#AB47BC', '#5C6BC0', '#26A69A']
    # çªå‡ºæ˜¾ç¤ºå æ¯”æœ€å¤§çš„éƒ¨åˆ†ï¼ˆè‡ªåŠ¨åˆ†ç¦»ï¼‰
    explode = [0.05 if v == max(prob_values) else 0 for v in prob_values]

    # ç»˜åˆ¶æ‰‡å½¢å›¾ï¼šautopctæ˜¾ç¤ºç™¾åˆ†æ¯”(ä¿ç•™2ä½å°æ•°)ï¼Œstartangleä»90åº¦å¼€å§‹ï¼Œé¡ºæ—¶é’ˆæ’åˆ—
    wedges, texts, autotexts = ax2.pie(
        prob_values,
        #labels=prob_labels,
        colors=colors,
        explode=explode,
        autopct='%.2f%%',
        startangle=90,
        textprops={'fontsize': 10},
        pctdistance=0.70,
        labeldistance=1.05
    )
    ax2.legend(
        wedges, legend_labels,
        loc='center left',  # å›¾ä¾‹ä½ç½®ï¼šå›¾çš„å³ä¾§
        bbox_to_anchor=(1, 0.5),  # é”šç‚¹å®šä½ï¼Œç¡®ä¿å›¾ä¾‹åœ¨å›¾å¤–å³ä¾§
        fontsize=7,
        title="å¥åº·çŠ¶æ€åˆ†å¸ƒ",
        title_fontsize=11
    )

    # æ‰‡å½¢å›¾æ ·å¼ç¾åŒ–
    ax2.set_title('è®¾å¤‡å¥åº·çŠ¶æ€æ¦‚ç‡åˆ†å¸ƒ', fontsize=16, pad=20, fontweight='bold')
    # ç™¾åˆ†æ¯”æ–‡å­—ç™½è‰²åŠ ç²—ï¼Œæ›´æ¸…æ™°
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontweight('bold')

    # ====================== 7. è°ƒæ•´å­å›¾é—´è· + ä¿å­˜å›¾ç‰‡ ======================
    plt.tight_layout(pad=3)  # è°ƒæ•´ä¸Šä¸‹å­å›¾é—´è·ï¼Œé¿å…æ ‡é¢˜é‡å 
    plt.savefig(img_path, dpi=dpi, bbox_inches='tight', facecolor='white')  # ä¿å­˜å›¾ç‰‡ï¼Œè£å‰ªç™½è¾¹
    plt.close()  # å…³é—­ç”»å¸ƒï¼Œé‡Šæ”¾å†…å­˜

def ger_data(selected_file,model_dir):
    df= pd.read_csv(selected_file)
    file_name = f'{BASE_DIR}/output/jiaobanji_prd/'+uuid.uuid4().hex
    json_data = predict_new_data(df,selected_file,model_dir,file_name)
    img_path=file_name+'.png'
    # æŠ¥å‘Šç”Ÿæˆ
    #report = generate_health_report(json.loads(json_data))
    report = generate_health_report([json_data])
    generate_device_analysis_chart(df[['rqjkwdsdz', 'rqjkwddqz',
        'rqjkzksdz', 'rqjkzkdqz',
        'bpdjjbsjsdz', 'bpdjjbsjdqz',
        'bpdjjbsdsdz', 'bpdjjbsddqz',
        'bpdjfssjsdz', 'bpdjfssjdqz',
        'bpdjfssdsdz', 'bpdjfssddqz']], json_data,img_path)
    return img_path,report

def process_input(selected_model_dir):


    """å¤„ç†å…¨å±€é€‰ä¸­çš„æµ‹è¯•æ–‡ä»¶ï¼Œè¿”å›å›¾è¡¨å’Œç»“æœ"""
    time.sleep(1)
    preset_info = f"æµ‹è¯•æ–‡ä»¶: {selected_preset}" if selected_preset else "æœªé€‰æ‹©æµ‹è¯•æ–‡ä»¶"
    model_info = f"æ¨¡å‹ç›®å½•: {selected_model_dir}"
    result =''
    # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†æµ‹è¯•æ–‡ä»¶
    if not selected_preset:
        return None, f"é”™è¯¯: è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\n{preset_info}\n{model_info}"
    else:
        model = create_model(model_name="TimesNet_cls", model_dir=selected_model_dir)
        filepath = selected_preset
        output = model.predict(filepath, batch_size=1)
        savepath = f"{BASE_DIR}/output/jiaobanji_prd"  # ç»“æœç›®å½•
        # è°ƒç”¨æ–°çš„æ–¹æ³•
        plot_path, report_content = ger_data(selected_preset,selected_model_dir)
        for res in output:
            #res.print()  ## æ‰“å°é¢„æµ‹çš„ç»“æ„åŒ–è¾“å‡º
            #res.save_to_img(save_path=savepath)
            res.save_to_json(save_path=savepath)

            separator = os.sep
            # ä¸ºä¸Šä¼ çš„å›¾ç‰‡ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            json_filename = selected_preset.split(separator)[-1].split('.')[0] + '_res.json'
            img_name = selected_preset.split(separator)[-1].split('.')[0] + '_res.png'
            with open(savepath+"/"+json_filename, 'r', encoding='utf-8') as file:
                data = json.load(file)
        #return savepath+"/"+img_name, data['classification']
        return plot_path, report_content

def set_selected(file_path, buttons, file_paths):
    """æ›´æ–°é€‰ä¸­çŠ¶æ€ï¼Œä¿®æ”¹æŒ‰é’®æ ·å¼å¹¶æ›´æ–°å…¨å±€å˜é‡"""
    global selected_preset
    selected_preset = file_path
    # è¿”å›æ‰€æœ‰æŒ‰é’®çš„æ ·å¼æ›´æ–°åˆ—è¡¨
    # å¯¹äºæ¯ä¸ªæŒ‰é’®ï¼Œå¦‚æœå®ƒå¯¹åº”çš„æ–‡ä»¶è·¯å¾„ä¸é€‰ä¸­çš„æ–‡ä»¶è·¯å¾„ç›¸åŒï¼Œåˆ™è®¾ç½®ä¸ºprimaryï¼ˆé«˜äº®ï¼‰ï¼Œå¦åˆ™è®¾ç½®ä¸ºsecondaryï¼ˆé»˜è®¤ï¼‰
    #return [gr.update(variant="primary" if fp == file_path else "secondary") for fp, btn in zip(file_paths, buttons)]
    # update_list = [gr.update(variant="primary") if fp == file_path else gr.update(variant="secondary") for fp, btn in zip(file_paths, buttons)]
    # print("æ›´æ–°åˆ—è¡¨é•¿åº¦ï¼š", len(update_list), "æŒ‰é’®åˆ—è¡¨é•¿åº¦ï¼š", len(buttons))  # å¿…é¡»ç›¸ç­‰ï¼
    # return update_list
    global selected_file
    selected_file = file_path

    # ä¿®å¤ç‚¹1ï¼šç¡®ä¿è¿”å›åˆ—è¡¨çš„é•¿åº¦å’Œé¡ºåºä¸buttonså®Œå…¨ä¸€è‡´
    update_list = []
    for fp in file_paths:  # åªéå†file_pathsï¼Œé¿å…btnå¹²æ‰°ï¼ˆbtnå¯¹è±¡ä¸å½±å“åˆ¤æ–­ï¼‰
        if fp == file_path:
            update_list.append(gr.update(variant="primary"))
        else:
            update_list.append(gr.update(variant="secondary"))
    return update_list + [None]

def create_interface():
    # ä»dataset/ç›®å½•åŠ¨æ€è¯»å–CSVæ–‡ä»¶
    cwru_dir = os.path.join(os.path.dirname(__file__), "dataset", "jiaobanji_prd")
    preset_files = {}

    # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–è€…æ­£ç¡®çš„ç›¸å¯¹è·¯å¾„
    if not os.path.exists(cwru_dir):
        # å°è¯•ä½¿ç”¨å…¶ä»–å¯èƒ½çš„è·¯å¾„
        alt_paths = [
            #"E:/ai-dataset/motor_fault_detect_/validation/positive_samples",
            f"{BASE_DIR}/dataset/jiaobanji_prd",
            "./dataset/jiaobanji_prd",
            "dataset/jiaobanji_prd",
        ]
        for path in alt_paths:
            if os.path.exists(path):
                cwru_dir = path
                break

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰CSVæ–‡ä»¶
    if os.path.exists(cwru_dir):
        for file_name in os.listdir(cwru_dir):
            if file_name.endswith('.csv'):
                file_path = os.path.join(cwru_dir, file_name)
                preset_files[file_path] = f"ğŸ“„ {file_name}"

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶
    if not preset_files:
        preset_files = {"dataset/jiaobanji_prd/t_n1.csv": "ğŸ“„ t_n1.csv"}

    # ä»model/dianji_modelç›®å½•è¯»å–å­ç›®å½•ä½œä¸ºæ¨¡å‹é€‰é¡¹
    model_dir = os.path.join(os.path.dirname(__file__), "model", "jiaobanji_prd")
    model_options = []  # å°†ä½¿ç”¨å…ƒç»„åˆ—è¡¨: [(å­ç›®å½•åç§°, å®Œæ•´è·¯å¾„)]

    if not os.path.exists(model_dir):
        # å°è¯•ä½¿ç”¨å…¶ä»–å¯èƒ½çš„è·¯å¾„
        alt_model_paths = [
            f"{BASE_DIR}/model/jiaobanji_prd",
            "./model/jiaobanji_prd",
            "model/jiaobanji_prd",
        ]
        for path in alt_model_paths:
            if os.path.exists(path):
                model_dir = path
                break

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰å­ç›®å½•
    if os.path.exists(model_dir):
        for item in os.listdir(model_dir):
            item_path = os.path.join(model_dir, item)
            if os.path.isdir(item_path):
                # æ·»åŠ å…ƒç»„(æ˜¾ç¤ºæ–‡æœ¬, å®é™…å€¼)
                model_options.append((item, item_path))

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤å€¼
    # if not model_options:
    #     default_model_name = "Timesnet_cls"
    #     default_model_dir = os.path.join(model_dir, default_model_name)
    #     model_options.append((default_model_name, default_model_dir))

    with gr.Blocks(title="æ…æ‹Œæœºæ•…éšœé¢„æµ‹åº”ç”¨") as demo:
        gr.Markdown("# ğŸš€ æ…æ‹Œæœºæ•…éšœé¢„æµ‹åº”ç”¨")
        placeholder = gr.Textbox(visible=False)  # æ–°å¢è¿™1è¡Œï¼Œæ— å…¶ä»–æ”¹åŠ¨
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### é€‰æ‹©æµ‹è¯•æ–‡ä»¶")

                # åŠ¨æ€åˆ›å»ºæ–‡ä»¶æŒ‰é’®
                buttons = []
                file_paths = list(preset_files.keys())
                for file_path, display_text in preset_files.items():
                    btn = gr.Button(display_text, variant="secondary", size="lg")
                    buttons.append(btn)

                # åœ¨åˆ›å»ºå®Œæ‰€æœ‰æŒ‰é’®åï¼Œä¸ºæ¯ä¸ªæŒ‰é’®ç»‘å®šç‚¹å‡»äº‹ä»¶
                for i, file_path in enumerate(file_paths):
                    def update_jt_btn(path, buttons=buttons, file_paths=file_paths):
                        return set_selected(path, buttons, file_paths)

                    # ç»‘å®špartialå‡½æ•°ï¼Œæ˜ç¡®ä¼ å…¥å½“å‰çš„file_path
                    buttons[i].click(
                        fn=partial(update_jt_btn, path=file_path),
                        inputs=[],
                        #outputs=buttons  # å¿…é¡»ç¡®ä¿outputsæ˜¯jt_buttonsåˆ—è¡¨æœ¬èº«
                        outputs = buttons + [placeholder],  # ä»…æ”¹è¿™ä¸€è¡Œ
                        show_progress = "hidden"  # ä¿ç•™ä¹‹å‰åŠ çš„å‚æ•°
                    )
                    # buttons[i].click(
                    #     fn=lambda path=file_path: set_selected(path, buttons, file_paths),
                    #     inputs=[],
                    #     outputs=buttons
                    # )

                # æ·»åŠ æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
                gr.Markdown("### é€‰æ‹©æ¨¡å‹")
                model_dropdown = gr.Dropdown(
                    choices=model_options,
                    label="æ¨¡å‹åˆ—è¡¨",
                    value=model_options[0][1] if model_options else ""  # ä½¿ç”¨å…ƒç»„çš„ç¬¬äºŒä¸ªå…ƒç´ ä½œä¸ºé»˜è®¤å€¼
                )

                process_btn = gr.Button("å¤„ç†", variant="primary")

            with gr.Column(scale=2):  # æ‰©å¤§ç»“æœå±•ç¤ºåŒºåŸŸ
                gr.Markdown("### åŸå§‹æŒ¯åŠ¨ä¿¡å·å›¾")
                plot_output = gr.Image(label="æ•°æ®æ›²çº¿", type="pil",buttons=['fullscreen'])

                gr.Markdown("### å¤„ç†ç»“æœ")
                output_text = gr.Textbox(label="é¢„æµ‹ç»“æœ", lines=6)

        # å¤„ç†æŒ‰é’®äº‹ä»¶ï¼ˆè¿”å›å›¾ç‰‡å’Œæ–‡æœ¬ç»“æœï¼‰
        process_btn.click(
            fn=process_input,
            inputs=[model_dropdown],
            outputs=[plot_output, output_text]
        )

    return demo


def main():
    # ä»å‘½ä»¤è¡Œå‚æ•°è·å–ç«¯å£å·ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤ç«¯å£7860
    port = 7861
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            if port < 1024 or port > 65535:
                print(f"è­¦å‘Šï¼šç«¯å£å· {port} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…(1024-65535)ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7860")
                port = 7860
        except ValueError:
            print(f"è­¦å‘Šï¼šæ— æ•ˆçš„ç«¯å£å·å‚æ•° '{sys.argv[1]}'ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7860")

    demo = create_interface()
    demo.launch(allowed_paths=[f'{BASE_DIR}/output'],server_name="0.0.0.0", server_port=port, share=False)


if __name__ == "__main__":
    main()