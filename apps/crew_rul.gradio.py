# -*- coding: utf-8 -*-
import gradio as gr
import pandas as pd
import numpy as np
import os
import sys
from tensorflow.keras.models import load_model
from tensorflow.keras import losses, metrics
from scipy import signal, stats
import glob
import pickle
from utils.app_utils import MultiDirectoryMonitor
from utils.app_utils import AppUtils as util
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Layer
from io import BytesIO
from PIL import Image
import matplotlib
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.app_utils import AppUtils as util
from matplotlib.patches import Rectangle, FancyBboxPatch
from pathlib import Path
matplotlib.use('Agg')
import logging

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# å…¨å±€å˜é‡
selected_data_path = None
selected_model_version = None
max_start_index = 0
file_count = 0
plt = util.auto_config_chinese_font()

# æ¨¡å‹ç¼“å­˜
model_cache = {}
scaler_cache = {}




class Config:

    WINDOW_SIZE = 25
    FS = 25600
    RUL_CAP = 150.0
    
    def __init__(self, model_version=4400):
        self.MODEL_VERSION = model_version
        self.BASE_DIR = Path(__file__).parent.parent
        self.MODEL_BASE_DIR = self.BASE_DIR / "model" / "crew_rul" / "model"
        self.RESTART_SIGNAL_FILENAME = ".restart_signal_crew_rul"
        self.EXAMPLE_DIR = self.BASE_DIR / "model" / "crew_rul" / "dataset"

    @property
    def MODEL_PATH(self):
        logging.info(self.MODEL_BASE_DIR)
        return self.MODEL_BASE_DIR / f"rul_model_v{self.MODEL_VERSION}.h5"

    @property
    def SCALER_PATH(self):
        return self.MODEL_BASE_DIR / f"scalers_v{self.MODEL_VERSION}.pkl"

class TemporalAttention(Layer):
    """æ—¶åºæ³¨æ„åŠ›æœºåˆ¶"""
    def __init__(self, **kwargs):
        super(TemporalAttention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(
            name='attention_weight',
            shape=(input_shape[-1], input_shape[-1]),
            initializer='glorot_uniform',
            trainable=True
        )
        self.b = self.add_weight(
            name='attention_bias',
            shape=(input_shape[-1],),
            initializer='zeros',
            trainable=True
        )
        super(TemporalAttention, self).build(input_shape)

    def call(self, inputs):
        e = K.tanh(K.dot(inputs, self.W) + self.b)
        a = K.softmax(e, axis=1)
        output = inputs * a
        return K.sum(output, axis=1)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[-1])

model_options = util.generate_paddlex_model_options(Config().MODEL_BASE_DIR)
config=None

def load_model_cached(model_version):
    """åŠ è½½æ¨¡å‹å¹¶ç¼“å­˜"""
    if model_version not in model_cache:
        config = Config(model_version=model_version)
        if not os.path.exists(config.MODEL_PATH) or not os.path.exists(config.SCALER_PATH):
            logging.error(f"æ‰¾ä¸åˆ°æ¨¡å‹v{model_version}æˆ–scaleræ–‡ä»¶")
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹v{model_version}æˆ–scaleræ–‡ä»¶")
        
        logging.info(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹ v{model_version}...")
        
        # ä½¿ç”¨ compile=False é¿å…æŸäº›åºåˆ—åŒ–é—®é¢˜
        model = load_model(config.MODEL_PATH, custom_objects={
            'TemporalAttention': TemporalAttention(),
            'mse': losses.MeanSquaredError(),
            'mae': metrics.MeanAbsoluteError()
        }, compile=False)
        
        # ä½¿ç”¨æ›´å®‰å…¨çš„ pickle åŠ è½½æ–¹å¼
        try:
            with open(config.SCALER_PATH, 'rb') as f:
                saved_data = pickle.load(f)
                scaler_X = saved_data['scaler_X']
        except (AttributeError, ModuleNotFoundError) as e:
            # å¦‚æœç›´æ¥åŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å…¼å®¹æ¨¡å¼
            logging.warning(f"âš ï¸ æ ‡å‡†åŠ è½½å¤±è´¥ï¼Œå°è¯•å…¼å®¹æ¨¡å¼: {e}")
            import sys
            import types
            
            # åˆ›å»ºä¸´æ—¶æ¨¡å—ä»¥æ”¯æŒ pickle åŠ è½½
            if '__main__' not in sys.modules or not hasattr(sys.modules['__main__'], 'Config'):
                main_module = sys.modules.get('__main__')
                if main_module is None:
                    main_module = types.ModuleType('__main__')
                    sys.modules['__main__'] = main_module
                
                main_module.Config = Config
                main_module.TemporalAttention = TemporalAttention
            
            with open(config.SCALER_PATH, 'rb') as f:
                saved_data = pickle.load(f)
                scaler_X = saved_data['scaler_X']
        
        model_cache[model_version] = model
        scaler_cache[model_version] = scaler_X
        logging.info(f"âœ… æ¨¡å‹ v{model_version} åŠ è½½å®Œæˆå¹¶å·²ç¼“å­˜")
    
    return model_cache[model_version], scaler_cache[model_version]

def create_features_for_signal(sig, fs=25600):
    """ä¸ºå•é€šé“ä¿¡å·æå–æ—¶åŸŸå’Œé¢‘åŸŸç‰¹å¾"""
    rms = np.sqrt(np.mean(sig**2))
    kurtosis = stats.kurtosis(sig)
    skewness = stats.skew(sig)
    peak_to_peak = np.max(sig) - np.min(sig)

    if rms > 1e-6:
        crest_factor = np.max(np.abs(sig)) / rms
    else:
        crest_factor = 0

    mean_sqrt = np.mean(np.sqrt(np.abs(sig)))
    if mean_sqrt > 1e-6:
        margin_factor = np.max(np.abs(sig)) / (mean_sqrt**2)
    else:
        margin_factor = 0

    mean_abs = np.mean(np.abs(sig))
    if mean_abs > 1e-6:
        impulse_factor = np.max(np.abs(sig)) / mean_abs
    else:
        impulse_factor = 0

    n = len(sig)
    freqs = np.fft.fftfreq(n, 1/fs)
    fft_vals = np.abs(np.fft.fft(sig))
    positive_freq_mask = freqs > 0
    freqs = freqs[positive_freq_mask]
    fft_vals = fft_vals[positive_freq_mask]

    total_power = np.sum(fft_vals)
    if total_power > 1e-6:
        freq_mean = np.average(freqs, weights=fft_vals)
        freq_std = np.sqrt(np.average((freqs - freq_mean)**2, weights=fft_vals))
    else:
        freq_mean = 0
        freq_std = 0

    return [rms, kurtosis, skewness, peak_to_peak, crest_factor, 
            margin_factor, impulse_factor, freq_mean, freq_std]

def load_and_process_csv_features(csv_path):
    """åŠ è½½CSVï¼Œå¤„ç†å¹¶æå–ç‰¹å¾å‘é‡"""
    try:
        data = pd.read_csv(csv_path)
        h = data.iloc[:, 0].values
        v = data.iloc[:, 1].values

        b, a = signal.butter(4, [20, 10000], btype='band', fs=25600)
        h = signal.filtfilt(b, a, h)
        v = signal.filtfilt(b, a, v)
        
        features_h = create_features_for_signal(h)
        features_v = create_features_for_signal(v)
        
        return np.array(features_h + features_v, dtype=np.float32)
    except Exception as e:
        print(f"è­¦å‘Š: å¤„ç†æ–‡ä»¶ {csv_path} æ—¶å‡ºé”™: {e}")
        return None

def create_visualization(predicted_rul, config):
    # ä¼˜åŒ–åçš„å­—ä½“é…ç½®
    FONT_CONFIG = {
        'value_xlarge': 42,    # ä¸»è¦æ•°å€¼
        'value_large': 32,     # æ¬¡è¦æ•°å€¼
        'title_large': 22,     # ä¸»æ ‡é¢˜
        'title_medium': 18,    # æ¬¡æ ‡é¢˜
        'label_medium': 16,    # æ ‡ç­¾
        'label_small': 14,     # å°æ ‡ç­¾
        'ticks': 11           # åˆ»åº¦
    }

    # ä¼˜åŒ–å›¾è¡¨å°ºå¯¸å’Œå¸ƒå±€ - è°ƒæ•´ä¸º16:9æ¯”ä¾‹
    fig = plt.figure(figsize=(16, 9))
    gs = fig.add_gridspec(2, 3, hspace=0.30, wspace=0.30, 
                         left=0.08, right=0.96, top=0.93, bottom=0.08)
    
    health_threshold = config.RUL_CAP * 0.5
    percentage = min(100, (predicted_rul / config.RUL_CAP) * 100)

    # ç¡®å®šå¥åº·çŠ¶æ€å’Œé¢œè‰²
    if predicted_rul > health_threshold:
        color = '#2ecc71'
        status = 'å¥åº·'
        icon = 'âœ“'
    elif predicted_rul > health_threshold * 0.5:
        color = '#f39c12'
        status = 'è½»å¾®é€€åŒ–'
        icon = 'âš '
    else:
        color = '#e74c3c'
        status = 'ä¸¥é‡é€€åŒ–'
        icon = 'âœ—'

    # 1. åŠåœ†ä»ªè¡¨ç›˜ (å·¦ä¸Šï¼Œå 2åˆ—)
    ax1 = fig.add_subplot(gs[0, :2], projection='polar')
    theta = np.linspace(0, np.pi, 100)
    r = np.ones_like(theta)
    
    # èƒŒæ™¯åŠåœ†
    ax1.plot(theta, r, color='#ecf0f1', linewidth=22, solid_capstyle='round', zorder=1)
    
    # å¡«å……åŠåœ†
    theta_fill = np.linspace(0, np.pi * (percentage / 100), 100)
    r_fill = np.ones_like(theta_fill)
    ax1.plot(theta_fill, r_fill, color=color, linewidth=22, solid_capstyle='round', zorder=2)
    
    ax1.set_ylim(0, 1.25)
    ax1.set_xlim(-0.2, np.pi + 0.2)
    ax1.axis('off')
    
    # ä¸­å¿ƒæ–‡å­—
    ax1.text(np.pi/2, 0.42, f'{predicted_rul:.1f}', 
            ha='center', va='center', 
            fontsize=FONT_CONFIG['value_xlarge'],
            fontweight='bold', color=color, family='monospace')
    ax1.text(np.pi/2, 0.15, 'å‰©ä½™å¯¿å‘½ (åˆ†é’Ÿ)', 
            ha='center', va='center', 
            fontsize=FONT_CONFIG['label_medium'],
            color='#7f8c8d')
    ax1.text(np.pi/2, -0.15, f'{icon} {status}', 
            ha='center', va='center', 
            fontsize=FONT_CONFIG['title_large'],
            fontweight='bold', color=color)

    # 2. å¥åº·åº¦ç™¾åˆ†æ¯”å¡ç‰‡ (å³ä¸Š)
    ax2 = fig.add_subplot(gs[0, 2])
    ax2.axis('off')
    
    # ç»˜åˆ¶æ¸å˜èƒŒæ™¯çŸ©å½¢
    rect = FancyBboxPatch((0.08, 0.2), 0.84, 0.65, 
                         boxstyle="round,pad=0.05", 
                         facecolor=color, alpha=0.12, 
                         edgecolor=color, linewidth=3)
    ax2.add_patch(rect)
    
    ax2.text(0.5, 0.68, f'{percentage:.1f}%', 
            ha='center', va='center', fontsize=FONT_CONFIG['value_large'], 
            fontweight='bold', color=color, transform=ax2.transAxes)
    ax2.text(0.5, 0.40, 'å¥åº·åº¦', 
            ha='center', va='center', fontsize=FONT_CONFIG['label_medium'], 
            color='#7f8c8d', transform=ax2.transAxes)
    ax2.set_xlim(0, 1)
    ax2.set_ylim(0, 1)

    # 3. è¿›åº¦æ¡å¼å¯¹æ¯” (å·¦ä¸‹ï¼Œå 2åˆ—)
    ax3 = fig.add_subplot(gs[1, :2])
    ax3.axis('off')
    ax3.set_xlim(-5, config.RUL_CAP * 1.08)
    ax3.set_ylim(-0.4, 2.2)
    
    # ç»˜åˆ¶å¥åº·é˜ˆå€¼çº¿
    bar_height = 0.65
    bar_y = 0.5
    
    # èƒŒæ™¯æ¡
    rect_bg = Rectangle((0, bar_y), config.RUL_CAP, bar_height, 
                       facecolor='#ecf0f1', edgecolor='#bdc3c7', linewidth=2.5)
    ax3.add_patch(rect_bg)
    
    # å½“å‰RULæ¡
    rect_rul = Rectangle((0, bar_y), predicted_rul, bar_height, 
                       facecolor=color, alpha=0.85, edgecolor=color, linewidth=2.5)
    ax3.add_patch(rect_rul)
    
    # å¥åº·é˜ˆå€¼æ ‡è®°çº¿
    ax3.plot([health_threshold, health_threshold], [0.25, 1.45], 
            color='#3498db', linewidth=2.5, linestyle='--', alpha=0.75)
    ax3.text(health_threshold, 1.60, f'å¥åº·é˜ˆå€¼\n{health_threshold:.1f}åˆ†é’Ÿ', 
            ha='center', va='bottom', fontsize=FONT_CONFIG['label_small'], 
            color='#3498db', fontweight='bold')
    
    # å½“å‰RULæ ‡è®°
    label_x = max(predicted_rul + 3, 8)
    ax3.text(label_x, bar_y + bar_height/2, f'{predicted_rul:.1f}', 
            ha='left', va='center', fontsize=FONT_CONFIG['label_medium'], 
            fontweight='bold', color=color)
    
    # æ ‡é¢˜
    ax3.text(-3, 1.95, 'å‰©ä½™å¯¿å‘½å¯¹æ¯”å›¾', 
            ha='left', va='center', fontsize=FONT_CONFIG['title_large'], 
            fontweight='bold', color='#2c3e50')
    
    # Xè½´åˆ»åº¦
    tick_y = -0.08
    ax3.text(0, tick_y, '0', ha='center', va='top', 
            fontsize=FONT_CONFIG['ticks'], color='#7f8c8d')
    ax3.text(config.RUL_CAP/2, tick_y, f'{config.RUL_CAP/2:.0f}', 
            ha='center', va='top', fontsize=FONT_CONFIG['ticks'], color='#7f8c8d')
    ax3.text(config.RUL_CAP, tick_y, f'{config.RUL_CAP:.0f}', 
            ha='center', va='top', fontsize=FONT_CONFIG['ticks'], color='#7f8c8d')

    # 4. çŠ¶æ€æŒ‡ç¤ºå¡ç‰‡ (å³ä¸‹)
    ax4 = fig.add_subplot(gs[1, 2])
    ax4.axis('off')
    ax4.set_xlim(0, 1)
    ax4.set_ylim(0, 1)
    
    # çŠ¶æ€å¡ç‰‡
    card_colors = {
        'å¥åº·': ('#d5f4e6', '#27ae60'),
        'è½»å¾®é€€åŒ–': ('#fef5e7', '#e67e22'),
        'ä¸¥é‡é€€åŒ–': ('#fadbd8', '#c0392b')
    }
    bg_color, border_color = card_colors[status]
    
    rect_card = FancyBboxPatch((0.08, 0.15), 0.84, 0.70, 
                             boxstyle="round,pad=0.05", 
                             facecolor=bg_color, 
                             edgecolor=border_color, linewidth=3)
    ax4.add_patch(rect_card)
    
    # çŠ¶æ€å›¾æ ‡å’Œæ–‡å­—
    ax4.text(0.5, 0.58, status, ha='center', va='center', 
            fontsize=FONT_CONFIG['title_large'], fontweight='bold', 
            color=border_color, transform=ax4.transAxes)
    ax4.text(0.5, 0.35, 'å½“å‰çŠ¶æ€', ha='center', va='center', 
            fontsize=FONT_CONFIG['label_medium'], color='#7f8c8d', 
            transform=ax4.transAxes)

    # è½¬æ¢ä¸ºå›¾åƒ
    buf = BytesIO()
    plt.savefig(buf, format='png', dpi=100, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    buf.seek(0)
    img = Image.open(buf)
    plt.close()

    return img

def get_file_count(data_path):
    """è·å–æ•°æ®æ–‡ä»¶å¤¹ä¸­CSVæ–‡ä»¶çš„æ•°é‡"""
    if data_path and os.path.exists(data_path):
        files = glob.glob(os.path.join(data_path, '*.csv'))
        return len(files)
    return 0

def get_available_models(model_dir):
    """æ‰«ææ¨¡å‹ç›®å½•ï¼Œè·å–å¯ç”¨çš„æ¨¡å‹ç‰ˆæœ¬"""
    models = []
    if os.path.exists(model_dir):
        model_files = glob.glob(os.path.join(model_dir, 'rul_model_v*.h5'))
        print(model_files)
        for model_file in sorted(model_files):
            basename = os.path.basename(model_file)
            version_str = basename.replace('rul_model_v', '').replace('.h5', '')
            display_name = basename.replace('.h5', '')
            try:
                scaler_file = os.path.join(model_dir, f'scalers_v{version_str}.pkl')
                if os.path.exists(scaler_file):
                    models.append((display_name, version_str))
            except ValueError:
                continue
    
    if not models:
        models = [("æ¨¡å‹ v4400 (é»˜è®¤)", 4400)]
    
    return models

def predict_rul(data_path, start_index, model_version):
    """å¯¹ç»™å®šçš„æ•°æ®æ–‡ä»¶å¤¹è¿›è¡ŒRULé¢„æµ‹"""
    config = Config(model_version=model_version)

    try:
        # ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹
        model, scaler_X = load_model_cached(model_version)
        
        key_func = lambda f: int(os.path.splitext(os.path.basename(f))[0])
        files = sorted(glob.glob(os.path.join(data_path, '*.csv')), key=key_func)
        
        if len(files) < config.WINDOW_SIZE:
            return None, f"âŒ é”™è¯¯: æ•°æ®ç‚¹ä¸è¶³ã€‚éœ€è¦è‡³å°‘ {config.WINDOW_SIZE} ä¸ªCSVæ–‡ä»¶ï¼Œä½†åªæ‰¾åˆ° {len(files)} ä¸ªã€‚"
        
        if start_index + config.WINDOW_SIZE > len(files):
            return None, f"âŒ é”™è¯¯: èµ·å§‹ç´¢å¼• {start_index} è¶…å‡ºèŒƒå›´ã€‚æœ€å¤§èµ·å§‹ç´¢å¼•ä¸º {len(files) - config.WINDOW_SIZE}ã€‚"
        
        latest_files = files[start_index:start_index + config.WINDOW_SIZE]
        features_list = []
        
        for f in latest_files:
            fv = load_and_process_csv_features(f)
            if fv is not None:
                features_list.append(fv)
        
        if len(features_list) < config.WINDOW_SIZE:
            return None, f"âŒ é”™è¯¯: æœ‰æ•ˆç‰¹å¾ä¸è¶³ {config.WINDOW_SIZE} ä¸ª"
        
        features = np.array(features_list)
        features_scaled = scaler_X.transform(features)
        input_data = np.expand_dims(features_scaled, axis=0)
        
        prediction_array = model.predict(input_data, verbose=0)
        log_rul_pred = prediction_array[0][0]
        predicted_rul = np.maximum(0, np.expm1(log_rul_pred))
        
        img = create_visualization(predicted_rul, config)
        
        health_threshold = config.RUL_CAP * 0.5
        if predicted_rul > health_threshold:
            status = "âœ… å¥åº·"
            recommendation = "è½´æ‰¿çŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­æ­£å¸¸è¿è¡Œã€‚"
            emoji = "ğŸŸ¢"
        elif predicted_rul > health_threshold * 0.5:
            status = "âš ï¸ è½»å¾®é€€åŒ–"
            recommendation = "å»ºè®®å®‰æ’å®šæœŸæ£€æŸ¥ï¼Œå¯†åˆ‡ç›‘æ§è½´æ‰¿çŠ¶æ€ã€‚"
            emoji = "ğŸŸ¡"
        else:
            status = "ğŸš¨ ä¸¥é‡é€€åŒ–"
            recommendation = "å¼ºçƒˆå»ºè®®å°½å¿«å®‰æ’ç»´æŠ¤æˆ–æ›´æ¢è½´æ‰¿ï¼"
            emoji = "ğŸ”´"
        
        result_text = f"""
        {emoji} é¢„æµ‹ç»“æœ
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        ğŸ”¢ å‰©ä½™ä½¿ç”¨å¯¿å‘½ (RUL): {predicted_rul:.2f} åˆ†é’Ÿ
        ğŸ“ˆ å¥åº·é˜ˆå€¼: {health_threshold:.2f} åˆ†é’Ÿ
        ğŸ“Š å¥åº·åº¦: {min(100, (predicted_rul/config.RUL_CAP)*100):.1f}%

        ğŸ¥ å¥åº·çŠ¶æ€: {status}

        ğŸ’¡ ç»´æŠ¤å»ºè®®:
        {recommendation}

        ğŸ“ æ•°æ®æ¥æº: {os.path.basename(data_path)}
        ğŸ¤– ä½¿ç”¨æ¨¡å‹: v{model_version} {'(å·²ç¼“å­˜)' if model_version in model_cache else ''}
        ğŸ“ é¢„æµ‹åŒºé—´: æ ·æœ¬ {start_index} åˆ° {start_index + config.WINDOW_SIZE - 1}
        ğŸ“Š ä½¿ç”¨æ•°æ®ç‚¹: {config.WINDOW_SIZE} ä¸ªæ ·æœ¬
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        """
        
        return img, result_text.strip()
        
    except Exception as e:
        return None, f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

def select_data_folder(folder_path):
    """é€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹å¹¶æ›´æ–°æ»‘å—èŒƒå›´"""
    global selected_data_path
    selected_data_path = folder_path
    
    file_count = get_file_count(folder_path)
    config = Config()
    max_start_index = max(0, file_count - config.WINDOW_SIZE)
    
    return (
        f"âœ… å·²é€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹: {os.path.basename(folder_path)}\nğŸ“Š æ€»æ–‡ä»¶æ•°: {file_count}",
        gr.update(maximum=max_start_index, value=min(1500, max_start_index), interactive=True)
    )

def select_model(model_version):
    """é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬"""
    global selected_model_version
    selected_model_version = model_version
    
    # é¢„åŠ è½½æ¨¡å‹åˆ°ç¼“å­˜
    try:
        load_model_cached(model_version)
        return f"âœ… å·²é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹: v{model_version}"
    except Exception as e:
        return f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"

def run_prediction(start_index, model_version):
    """è¿è¡Œé¢„æµ‹"""
    global selected_data_path
    if selected_data_path is None:
        return None, "âš ï¸ è¯·å…ˆé€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹ï¼"
    
    return predict_rul(selected_data_path, start_index, model_version)

def create_interface():
    config = Config()
    data_base_dir = config.EXAMPLE_DIR
    model_dir = config.MODEL_BASE_DIR
    
    data_folders = []
    if os.path.exists(data_base_dir):
        for item in os.listdir(data_base_dir):
            item_path = os.path.join(data_base_dir, item)
            if os.path.isdir(item_path):
                data_folders.append((item, item_path))

    if not data_folders:
        data_folders = [("ç¤ºä¾‹æ•°æ®", data_base_dir)]
    
    available_models = get_available_models(model_dir)

    health_check_js = '''
    () => {
        let isConnected = true;
        setInterval(async () => {
            try {
                await fetch('/');
                if (!isConnected) {
                    console.log("æˆåŠŸé‡æ–°è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ­£åœ¨åˆ·æ–°é¡µé¢...");
                    location.reload();
                }
                isConnected = true;
            } catch (e) {
                if (isConnected) {
                    console.log("ä¸æœåŠ¡å™¨çš„è¿æ¥å·²æ–­å¼€ï¼Œç­‰å¾…é‡æ–°è¿æ¥...");
                }
                isConnected = false;
            }
        }, 2000);
    }
    '''
    
    with gr.Blocks(title="ğŸ”§ è½´æ‰¿å‰©ä½™å¯¿å‘½é¢„æµ‹ç³»ç»Ÿ",  js=health_check_js) as iface:
        gr.Markdown("""
        # ğŸ”§ è½´æ‰¿å‰©ä½™å¯¿å‘½é¢„æµ‹ç³»ç»Ÿ
        ### åŸºäºæ·±åº¦å­¦ä¹ çš„æ™ºèƒ½é¢„æµ‹æ€§ç»´æŠ¤è§£å†³æ–¹æ¡ˆ
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“‚ æ•°æ®æºé€‰æ‹©")
                
                data_dropdown = gr.Dropdown(
                    choices=data_folders,
                    label="é€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹",
                    value=data_folders[0][1] if data_folders else "",
                    interactive=True
                )
                
                selection_status = gr.Textbox(
                    label="å½“å‰é€‰æ‹©",
                    value="",
                    interactive=False,
                    lines=2
                )
                
                gr.Markdown("### ğŸ¤– æ¨¡å‹é€‰æ‹©")
                
                model_dropdown = gr.Dropdown(
                    choices=available_models,
                    label="é€‰æ‹©é¢„æµ‹æ¨¡å‹",
                    value=available_models[0][1] if available_models else 4400,
                    interactive=True
                )
                
                model_status = gr.Textbox(
                    label="æ¨¡å‹çŠ¶æ€",
                    value=f"âœ… å·²é€‰æ‹©æ¨¡å‹: v{available_models[0][1]}" if available_models else "",
                    interactive=False,
                    lines=1
                )
                
                gr.Markdown("### ğŸšï¸ é¢„æµ‹åŒºé—´é€‰æ‹©")
                
                start_index_slider = gr.Slider(
                    minimum=0,
                    maximum=1500,
                    value=1500,
                    step=1,
                    label="èµ·å§‹ç´¢å¼•ï¼ˆé€‰æ‹©é¢„æµ‹çš„èµ·å§‹ä½ç½®ï¼‰",
                    info="æ»‘å—èŒƒå›´ä¼šæ ¹æ®æ–‡ä»¶æ•°é‡è‡ªåŠ¨è°ƒæ•´",
                    interactive=True
                )
                
                gr.Markdown("---")
                
                predict_btn = gr.Button(
                    "ğŸš€ å¼€å§‹é¢„æµ‹",
                    variant="primary",
                    size="lg"
                )
                
                gr.Markdown("""
                ---
                ### â„¹ï¸ ä½¿ç”¨è¯´æ˜
                1. ä»ä¸‹æ‹‰èœå•é€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹
                2. é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬ï¼ˆé¦–æ¬¡åŠ è½½ä¼šç¼“å­˜ï¼‰
                3. ä½¿ç”¨æ»‘å—é€‰æ‹©é¢„æµ‹çš„èµ·å§‹ä½ç½®
                4. ç‚¹å‡»"å¼€å§‹é¢„æµ‹"æŒ‰é’®
                5. æŸ¥çœ‹é¢„æµ‹ç»“æœå’Œç»´æŠ¤å»ºè®®
                """)
            
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ“Š é¢„æµ‹ç»“æœå¯è§†åŒ–")
                
                result_plot = gr.Image(
                    label="å¥åº·çŠ¶æ€ä»ªè¡¨ç›˜",
                    type="pil",
                    height=500
                )
                
                gr.Markdown("### ğŸ“‹ è¯¦ç»†æŠ¥å‘Š")
                
                result_text = gr.Textbox(
                    label="åˆ†æç»“æœ",
                    lines=15,
                    max_lines=20,
                    interactive=False
                )
        
        # ç»‘å®šäº‹ä»¶
        data_dropdown.change(
            fn=select_data_folder,
            inputs=[data_dropdown],
            outputs=[selection_status, start_index_slider]
        )
        
        model_dropdown.change(
            fn=select_model,
            inputs=[model_dropdown],
            outputs=[model_status]
        )
        
        predict_btn.click(
            fn=run_prediction,
            inputs=[start_index_slider, model_dropdown],
            outputs=[result_plot, result_text]
        )
        
        # é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªé€‰é¡¹å¹¶é¢„åŠ è½½æ¨¡å‹
        def init_interface():
            global selected_data_path, selected_model_version
            
            data_path = data_folders[0][1] if data_folders else ""
            model_version = available_models[0][1] if available_models else 4400
            
            # æ›´æ–°å…¨å±€å˜é‡
            selected_data_path = data_path
            selected_model_version = model_version
            
            # é¢„åŠ è½½æ¨¡å‹
            try:
                load_model_cached(model_version)
                model_msg = f"âœ… å·²é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹: v{model_version}"
            except Exception as e:
                model_msg = f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
            
            file_count = get_file_count(data_path)
            config = Config()
            max_start_index = max(0, file_count - config.WINDOW_SIZE)
            
            data_msg = f"âœ… å·²é€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹: {os.path.basename(data_path)}\nğŸ“Š æ€»æ–‡ä»¶æ•°: {file_count}"
            
            return (
                data_msg,
                gr.update(maximum=max_start_index, value=min(1500, max_start_index), interactive=True),
                model_msg
            )
        
        iface.load(
            fn=init_interface,
            outputs=[selection_status, start_index_slider, model_status]
        )

    return iface

def main():
    config = Config()    
    monitor_manager = MultiDirectoryMonitor(restart_signal_file_name=config.RESTART_SIGNAL_FILENAME)
    monitor_manager.add_directory(config.MODEL_BASE_DIR)
    monitor_manager.add_directory(config.EXAMPLE_DIR)
    if not monitor_manager.start_all():
        print("âŒ å¯åŠ¨ç›®å½•ç›‘æ§å¤±è´¥")
        return
    port = 7863
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            if port < 1024 or port > 65535:
                logging.warning(f"è­¦å‘Šï¼šç«¯å£å· {port} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…(1024-65535)ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7863")
                port = 7863
        except ValueError:
            logging.warning(f"è­¦å‘Šï¼šæ— æ•ˆçš„ç«¯å£å·å‚æ•° '{sys.argv[1]}'ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7863")

    iface = create_interface()
    try:
        iface.launch(server_name="0.0.0.0", server_port=port, share=False)
    finally:
        monitor_manager.stop_all(join_threads=True)

if __name__ == "__main__":
    main()
