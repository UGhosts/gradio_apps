from utils.app_utils import AppUtils as util
from utils.app_utils import MultiDirectoryMonitor


import os
import sys
# é€‰æ‹©ä½¿ç”¨0å·å¡
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
import os.path as osp
import numpy as np
import math
import cv2
import paddlex as pdx
import gradio as gr
from PIL import Image
import logging

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


METER_SHAPE = 512
CIRCLE_CENTER = [256, 256]
CIRCLE_RADIUS = 250
PI = 3.1415926536
LINE_HEIGHT = 120
LINE_WIDTH = 1570
TYPE_THRESHOLD = 40
METER_CONFIG = [{
    'scale_value': 25.0 / 50.0,
    'range': 25.0,
    'unit': "(MPa)"
}, {
    'scale_value': 1.6 / 32.0,
    'range': 1.6,
    'unit': "(MPa)"
}]

from pathlib import Path

# --- æ¨¡å‹ç›®å½•é…ç½® ---
BASE_DIR = Path(__file__).parent.parent
MODEL_BASE_DIR = BASE_DIR / "model" / "industrail_metric_det" / "model"
RESTART_SIGNAL_FILENAME = ".restart_signal_industrai_meter"
EXAMPLE_DIR = BASE_DIR / "dataset" / "industrail_metric_det"

class MeterReader:
    def __init__(self, detector_dir, segmenter_dir):
        if not osp.exists(detector_dir):
            raise Exception("Model path {} does not exist".format(
                detector_dir))
        if not osp.exists(segmenter_dir):
            raise Exception("Model path {} does not exist".format(
                segmenter_dir))
        
        self.detector = pdx.create_model(model_name='PP-YOLOE_plus-S', model_dir=detector_dir)
        self.segmenter = pdx.create_model(model_name='SegFormer-B1', model_dir=segmenter_dir)

    def predict(self,
                im_file,
                use_erode=True,
                erode_kernel=4,
                score_threshold=0.5,
                seg_batch_size=2):
        if isinstance(im_file, str):
            im = cv2.imread(im_file).astype('float32')
        else:
            im = im_file.copy().astype('float32')
        
        # Get detection results - PaddleX 3.2 é¢„æµ‹æ¥å£
        det_results = self.detector.predict(im_file if isinstance(im_file, str) else im)
        
        # é€‚é…æ–°çš„ç»“æœæ ¼å¼
        det_result = list(det_results)[0]
        if det_result.get('boxes', None):
            # æ–°ç‰ˆæœ¬å¯èƒ½è¿”å›ä¸åŒçš„æ•°æ®ç»“æ„
            filtered_results = list()
            boxes = det_result.get('boxes', None)
            
            for box in boxes:
                score = box.get('score', None)
                if score and score > score_threshold:
                    # æå–åæ ‡
                    xmin = box['coordinate'][0]
                    ymin = box['coordinate'][1]
                    xmax = box['coordinate'][2]
                    ymax = box['coordinate'][3]
                    result_dict = {
                        'bbox': [xmin, ymin, xmax - xmin, ymax - ymin],
                        'score': score,
                        'category_id': getattr(box, 'cls_id', 0),
                        'category': getattr(box, 'label', 'meter')
                    }
                    filtered_results.append(result_dict)
        else:
            # å…¼å®¹æ—§æ ¼å¼
            filtered_results = list()
            for res in det_result:
                if res['score'] > score_threshold:
                    filtered_results.append(res)

        resized_meters = list()
        for res in filtered_results:
            # Crop the bbox area
            xmin, ymin, w, h = res['bbox']
            xmin = max(0, int(xmin))
            ymin = max(0, int(ymin))
            xmax = min(im.shape[1], int(xmin + w - 1))
            ymax = min(im.shape[0], int(ymin + h - 1))
            sub_image = im[ymin:(ymax + 1), xmin:(xmax + 1), :]

            # Resize the image with shape (METER_SHAPE, METER_SHAPE)
            meter_shape = sub_image.shape
            scale_x = float(METER_SHAPE) / float(meter_shape[1])
            scale_y = float(METER_SHAPE) / float(meter_shape[0])
            meter_meter = cv2.resize(
                sub_image,
                None,
                None,
                fx=scale_x,
                fy=scale_y,
                interpolation=cv2.INTER_LINEAR)
            meter_meter = meter_meter.astype('float32')
            resized_meters.append(meter_meter)

        meter_num = len(resized_meters)
        seg_results = list()
        
        # åˆ†å‰²é¢„æµ‹
        for i in range(0, meter_num, seg_batch_size):
            im_size = min(meter_num, i + seg_batch_size)
            for j in range(i, im_size):
                # å•ç‹¬é¢„æµ‹æ¯ä¸ªä»ªè¡¨å›¾åƒ
                seg_result_generator = self.segmenter.predict(resized_meters[j])
                seg_result = list(seg_result_generator)[0]
                # å¤„ç†åˆ†å‰²ç»“æœ
                if seg_result.get('label_map', None) is not None:
                    label_map = seg_result.get('label_map')
                elif seg_result.get('pred', None) is not None and np.any(seg_result.get('pred', None)):
                    label_map = seg_result['pred']
                else:
                    label_map = seg_result if isinstance(seg_result, np.ndarray) else seg_result[0]
                label_map_uint8 = label_map.astype(np.uint8)
                if use_erode:
                    kernel = np.ones((erode_kernel, erode_kernel), np.uint8)
                    label_map = cv2.erode(label_map_uint8, kernel)
                
                seg_results.append({'label_map': label_map})

        results = list()
        for i, seg_result in enumerate(seg_results):
            result = self.read_process(seg_result['label_map'])
            results.append(result)

        meter_values = list()
        for i, result in enumerate(results):
            if result['scale_num'] > TYPE_THRESHOLD:
                value = result['scales'] * METER_CONFIG[0]['scale_value']
            else:
                value = result['scales'] * METER_CONFIG[1]['scale_value']
            meter_values.append(value)

        # ç”Ÿæˆå¯è§†åŒ–ç»“æœå›¾åƒ
        result_image = self.visualize_results(im_file, filtered_results, meter_values)
        
        return result_image, meter_values, filtered_results

    def visualize_results(self, im_file, filtered_results, meter_values):
        """
        å¯è§†åŒ–æ£€æµ‹å’Œè¯»æ•°ç»“æœï¼Œè¿”å›PILå›¾åƒ
        """
        if isinstance(im_file, str):
            im = cv2.imread(im_file)
        else:
            im = im_file.copy()
        
        # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†å’Œè¯»æ•°å€¼
        for i, (res, value) in enumerate(zip(filtered_results, meter_values)):
            xmin, ymin, w, h = res['bbox']
            xmin, ymin = int(xmin), int(ymin)
            xmax, ymax = int(xmin + w), int(ymin + h)
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            cv2.rectangle(im, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
            
            # æ·»åŠ è¯»æ•°æ–‡æœ¬
            if value != -1:
                text = f"Meter {i+1}: {value:.2f} MPa"
            else:
                text = f"Meter {i+1}: Unable to read"
            cv2.putText(im, text, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 
                       0.6, (0, 255, 0), 2)
        
        # è½¬æ¢ä¸ºRGBæ ¼å¼å¹¶è¿”å›PILå›¾åƒ
        im_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
        return Image.fromarray(im_rgb)

    def read_process(self, label_maps):
        # Convert the circular meter into rectangular meter
        line_images = self.creat_line_image(label_maps)
        # Convert the 2d meter into 1d meter
        scale_data, pointer_data = self.convert_1d_data(line_images)
        # Fliter scale data whose value is lower than the mean value
        self.scale_mean_filtration(scale_data)
        # Get scale_num, scales and ratio of meters
        result = self.get_meter_reader(scale_data, pointer_data)
        return result

    def creat_line_image(self, meter_image):
        if len(meter_image.shape) == 3:
            meter_image = meter_image[0]  # å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        line_image = np.zeros((LINE_HEIGHT, LINE_WIDTH), dtype=np.uint8)
        for row in range(LINE_HEIGHT):
            for col in range(LINE_WIDTH):
                theta = PI * 2 / LINE_WIDTH * (col + 1)
                rho = CIRCLE_RADIUS - row - 1
                x = int(CIRCLE_CENTER[0] + rho * math.cos(theta) + 0.5)
                y = int(CIRCLE_CENTER[1] - rho * math.sin(theta) + 0.5)
                line_image[row, col] = meter_image[x, y]
        return line_image

    def convert_1d_data(self, meter_image):
        scale_data = np.zeros((LINE_WIDTH), dtype=np.uint8)
        pointer_data = np.zeros((LINE_WIDTH), dtype=np.uint8)
        for col in range(LINE_WIDTH):
            for row in range(LINE_HEIGHT):
                if meter_image[row, col] == 1:
                    pointer_data[col] += 1
                elif meter_image[row, col] == 2:
                    scale_data[col] += 1
        return scale_data, pointer_data

    def scale_mean_filtration(self, scale_data):
        mean_data = np.mean(scale_data)
        for col in range(LINE_WIDTH):
            if scale_data[col] < mean_data:
                scale_data[col] = 0

    def get_meter_reader(self, scale_data, pointer_data):
        scale_flag = False
        pointer_flag = False
        one_scale_start = 0
        one_scale_end = 0
        one_pointer_start = 0
        one_pointer_end = 0
        scale_location = list()
        pointer_location = 0
        for i in range(LINE_WIDTH - 1):
            if scale_data[i] > 0 and scale_data[i + 1] > 0:
                if scale_flag == False:
                    one_scale_start = i
                    scale_flag = True
            if scale_flag:
                if scale_data[i] == 0 and scale_data[i + 1] == 0:
                    one_scale_end = i - 1
                    one_scale_location = (one_scale_start + one_scale_end) / 2
                    scale_location.append(one_scale_location)
                    one_scale_start = 0
                    one_scale_end = 0
                    scale_flag = False
            if pointer_data[i] > 0 and pointer_data[i + 1] > 0:
                if pointer_flag == False:
                    one_pointer_start = i
                    pointer_flag = True
            if pointer_flag:
                if pointer_data[i] == 0 and pointer_data[i + 1] == 0:
                    one_pointer_end = i - 1
                    pointer_location = (
                        one_pointer_start + one_pointer_end) / 2
                    one_pointer_start = 0
                    one_pointer_end = 0
                    pointer_flag = False

        scale_num = len(scale_location)
        scales = -1
        ratio = -1
        if scale_num > 0:
            for i in range(scale_num - 1):
                if scale_location[
                        i] <= pointer_location and pointer_location < scale_location[
                            i + 1]:
                    scales = i + (pointer_location - scale_location[i]) / (
                        scale_location[i + 1] - scale_location[i] + 1e-05) + 1
            ratio = (pointer_location - scale_location[0]) / (
                scale_location[scale_num - 1] - scale_location[0] + 1e-05)
        result = {'scale_num': scale_num, 'scales': scales, 'ratio': ratio}
        return result


# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹å®ä¾‹å’Œé€‰é¡¹
meter_reader = None
model_options = util.generate_paddlex_model_options(MODEL_BASE_DIR)

def initialize_model(detector_dir, segmenter_dir):
    """åˆå§‹åŒ–æ¨¡å‹"""
    global meter_reader
    try:
        meter_reader = MeterReader(detector_dir, segmenter_dir)
        return "âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"

def predict_meter_reading(image, detector_model, segmenter_model, use_erode, erode_kernel, score_threshold):
    """é¢„æµ‹ä»ªè¡¨è¯»æ•°çš„ä¸»å‡½æ•°"""
    global meter_reader
    
    detector_dir = model_options[detector_model]
    segmenter_dir = model_options[segmenter_model]
    
    if image is None:
        return None, "âŒ è¯·ä¸Šä¼ å›¾ç‰‡ï¼", "", "âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åŠ è½½æ¨¡å‹
    if meter_reader is None:
        status = initialize_model(detector_dir, segmenter_dir)
        if "å¤±è´¥" in status:
            return None, status, "", "âŒ æ¨¡å‹åŠ è½½å¤±è´¥"
    
    try:
        # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        image_array = np.array(image)
        
        # æ‰§è¡Œé¢„æµ‹
        result_image, meter_values, filtered_results = meter_reader.predict(
            image_array,
            use_erode=use_erode,
            erode_kernel=erode_kernel,
            score_threshold=score_threshold
        )
        
        # ç”Ÿæˆç»“æœæ–‡æœ¬
        if len(meter_values) == 0:
            result_text = "âŒ æœªæ£€æµ‹åˆ°ä»»ä½•ä»ªè¡¨"
            summary_text = "æœªæ‰¾åˆ°ä»ªè¡¨"
            status_text = "âš ï¸ æœªæ£€æµ‹åˆ°ä»ªè¡¨"
        else:
            result_lines = []
            valid_readings = []
            
            for i, value in enumerate(meter_values):
                if value != -1:
                    result_lines.append(f"ä»ªè¡¨ {i+1}: {value:.3f} MPa")
                    valid_readings.append(value)
                else:
                    result_lines.append(f"ä»ªè¡¨ {i+1}: æ— æ³•è¯»å–")
            
            result_text = "ğŸ“Š æ£€æµ‹ç»“æœ:\n" + "\n".join(result_lines)
            
            if valid_readings:
                summary_text = f"å…±æ£€æµ‹åˆ° {len(meter_values)} ä¸ªä»ªè¡¨ï¼ŒæˆåŠŸè¯»å– {len(valid_readings)} ä¸ª"
                status_text = f"âœ… æˆåŠŸè¯»å– {len(valid_readings)}/{len(meter_values)} ä¸ªä»ªè¡¨"
            else:
                summary_text = f"å…±æ£€æµ‹åˆ° {len(meter_values)} ä¸ªä»ªè¡¨ï¼Œä½†æ— æ³•è¯»å–æ•°å€¼"
                status_text = "âš ï¸ æ£€æµ‹åˆ°ä»ªè¡¨ä½†æ— æ³•è¯»å–"
        
        return result_image, result_text, summary_text, status_text
        
    except Exception as e:
        error_msg = f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        return None, error_msg, "", "âŒ é¢„æµ‹å¤±è´¥"


# åˆ›å»ºGradioç•Œé¢
def create_gradio_interface():
    health_check_js = '''
    () => {
        let isConnected = true;
        setInterval(async () => {
            try {
                await fetch('/');
                if (!isConnected) {
                    console.log("æˆåŠŸé‡æ–°è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ­£åœ¨åˆ·æ–°é¡µé¢...");
                    location.reload();
                }
                isConnected = true;
            } catch (e) {
                if (isConnected) {
                    console.log("ä¸æœåŠ¡å™¨çš„è¿æ¥å·²æ–­å¼€ï¼Œç­‰å¾…é‡æ–°è¿æ¥...");
                }
                isConnected = false;
            }
        }, 2000);
    }
    '''
    with gr.Blocks(title="æ™ºèƒ½ä»ªè¡¨è¯»æ•°ç³»ç»Ÿ", js=health_check_js) as iface:        
        gr.Markdown("""
        # ğŸ¯ æ™ºèƒ½ä»ªè¡¨è¯»æ•°ç³»ç»Ÿ
        **åŠŸèƒ½ç‰¹ç‚¹ï¼š** åŸºäºæ·±åº¦å­¦ä¹ çš„å‹åŠ›è¡¨è‡ªåŠ¨è¯»æ•°å·¥å…·
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                initial_examples = util.get_current_examples(EXAMPLE_DIR)
                example_gallery = gr.Gallery(
                    value=initial_examples,
                    label="ç‚¹å‡»é€‰æ‹©ç¤ºä¾‹",
                    show_label=False,
                    elem_id="example_gallery",
                    columns=4,
                    rows=1,
                    height=200,
                    allow_preview=False
                )
                # æ¨¡å‹é…ç½®åŒºåŸŸ
                gr.Markdown("### ğŸ”§ æ¨¡å‹é…ç½®")
                with gr.Group():
                    detector_dropdown = gr.Dropdown(
                        choices=list(model_options.keys()),
                        value=list(model_options.keys())[1] if model_options else None,
                        label="æ£€æµ‹æ¨¡å‹",
                        info="é€‰æ‹©ç”¨äºæ£€æµ‹ä»ªè¡¨çš„æ¨¡å‹è·¯å¾„"
                    )
                    
                    segmenter_dropdown = gr.Dropdown(
                        choices=list(model_options.keys()),
                        value=list(model_options.keys())[0] if model_options else None,
                        label="åˆ†å‰²æ¨¡å‹",
                        info="é€‰æ‹©ç”¨äºåˆ†å‰²æŒ‡é’ˆå’Œåˆ»åº¦çš„æ¨¡å‹è·¯å¾„"
                    )
                
                # å‚æ•°é…ç½®åŒºåŸŸ
                gr.Markdown("### âš™ï¸ æ£€æµ‹å‚æ•°")
                with gr.Group():
                    score_threshold = gr.Slider(
                        minimum=0.1, 
                        maximum=0.9, 
                        value=0.5, 
                        step=0.1, 
                        label="æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼",
                        info="ä½äºæ­¤å€¼çš„æ£€æµ‹ç»“æœå°†è¢«è¿‡æ»¤"
                    )
                    
                    with gr.Row():
                        use_erode = gr.Checkbox(
                            label="ä½¿ç”¨å½¢æ€å­¦è…èš€", 
                            value=True,
                            info="å‡å°‘åˆ†å‰²å™ªå£°"
                        )
                        erode_kernel = gr.Slider(
                            minimum=1, 
                            maximum=10, 
                            value=4, 
                            step=1, 
                            label="è…èš€æ ¸å¤§å°",
                            info="å€¼è¶Šå¤§è…èš€æ•ˆæœè¶Šå¼º"
                        )
                
                # é¢„æµ‹æŒ‰é’®å’ŒçŠ¶æ€æ˜¾ç¤º
                predict_btn = gr.Button("ğŸ” å¼€å§‹è¯»æ•°", variant="primary", size="lg")
                        
                 # ä½¿ç”¨è¯´æ˜
                with gr.Accordion("ğŸ“‹ ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("""
                    **ğŸ“‹ ä½¿ç”¨æ­¥éª¤**
                    
                    1. **æ¨¡å‹é€‰æ‹©**: ä»ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©åˆé€‚çš„æ£€æµ‹å™¨å’Œåˆ†å‰²å™¨æ¨¡å‹
                    2. **ä¸Šä¼ å›¾ç‰‡**: ä¸Šä¼ åŒ…å«å‹åŠ›è¡¨çš„å›¾ç‰‡ï¼ˆæ”¯æŒJPG, PNG, BMPæ ¼å¼ï¼‰
                    3. **è°ƒæ•´å‚æ•°**: æ ¹æ®éœ€è¦è°ƒæ•´æ£€æµ‹ç½®ä¿¡åº¦å’Œå½¢æ€å­¦å¤„ç†å‚æ•°
                    4. **å¼€å§‹è¯»æ•°**: ç‚¹å‡»"å¼€å§‹è¯»æ•°"æŒ‰é’®è¿›è¡Œé¢„æµ‹
                    5. **æŸ¥çœ‹ç»“æœ**: åœ¨å³ä¾§æŸ¥çœ‹å¸¦æœ‰æ ‡æ³¨çš„ç»“æœå›¾ç‰‡å’Œå…·ä½“è¯»æ•°å€¼
                    
                    **âš™ï¸ å‚æ•°è¯´æ˜**
                    
                    - **æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼**: æ§åˆ¶æ£€æµ‹çš„æ•æ„Ÿåº¦ï¼Œå€¼è¶Šé«˜æ£€æµ‹è¶Šä¸¥æ ¼
                    - **ä½¿ç”¨å½¢æ€å­¦è…èš€**: å¯¹åˆ†å‰²ç»“æœè¿›è¡Œåå¤„ç†ï¼Œå¯ä»¥å‡å°‘å™ªå£°
                    - **è…èš€æ ¸å¤§å°**: è…èš€æ“ä½œçš„å¼ºåº¦ï¼Œé€‚å½“è°ƒæ•´å¯ä»¥æ”¹å–„è¯»æ•°å‡†ç¡®æ€§
                    """)
            
            with gr.Column(scale=1):
                # å›¾ç‰‡ä¸Šä¼ åŒºåŸŸ
                gr.Markdown("### ğŸ“· ä¸Šä¼ å›¾ç‰‡")
                input_image = gr.Image(
                    label="é€‰æ‹©åŒ…å«ä»ªè¡¨çš„å›¾ç‰‡", 
                    type="pil",
                    height=300,
                    sources=['upload']
                )
                
                gr.Markdown("### ğŸ“Š æ£€æµ‹ç»“æœ")
                
                # ç»“æœå›¾ç‰‡æ˜¾ç¤º
                output_image = gr.Image(
                    label="æ£€æµ‹ç»“æœå›¾ç‰‡", 
                    height=400,
                    show_label=True
                )
                
                # ç»“æœæ‘˜è¦
                summary_text = gr.Textbox(
                    label="æ£€æµ‹æ‘˜è¦", 
                    interactive=False,
                    show_label=True
                )
                
                # è¯¦ç»†ç»“æœ
                result_text = gr.Textbox(
                    label="è¯¦ç»†ç»“æœ", 
                    lines=8, 
                    interactive=False,
                    show_label=True
                )
        
        def select_example(evt: gr.SelectData):
            current_examples = util.get_current_examples(EXAMPLE_DIR)
            if current_examples and evt.index < len(current_examples):
                selected_path = current_examples[evt.index]
                return selected_path
            return None

        example_gallery.select(select_example, None, outputs=[input_image])
        
        # äº‹ä»¶ç»‘å®š
        predict_btn.click(
            predict_meter_reading,
            inputs=[
                input_image, 
                detector_dropdown, 
                segmenter_dropdown,
                use_erode, 
                erode_kernel, 
                score_threshold
            ],
            outputs=[output_image, result_text, summary_text]
        )
    
    return iface


def main():
    monitor_manager = MultiDirectoryMonitor(restart_signal_file_name=RESTART_SIGNAL_FILENAME)
    monitor_manager.add_directory(MODEL_BASE_DIR)
    monitor_manager.add_directory(EXAMPLE_DIR)
    if not monitor_manager.start_all():
        logging.error("âŒ å¯åŠ¨ç›®å½•ç›‘æ§å¤±è´¥")
        return
    port = 7862
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            if port < 1024 or port > 65535:
                logging.warning(f"è­¦å‘Šï¼šç«¯å£å· {port} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…(1024-65535)ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£{port}")
                port = port
        except ValueError:
            logging.warning(f"è­¦å‘Šï¼šæ— æ•ˆçš„ç«¯å£å·å‚æ•° '{sys.argv[1]}'ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£{port}")
    iface = create_gradio_interface()
    try:
        iface.launch(
            server_name="0.0.0.0",
            server_port=port,
            share=False,
        )
    finally:
        # åº”ç”¨å…³é—­æ—¶åœæ­¢ç›‘æ§
        monitor_manager.stop_all(join_threads=True)


if __name__ == '__main__':
    main()