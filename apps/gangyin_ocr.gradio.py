import gradio as gr
import time
import sys
import os
import json
import matplotlib.pyplot as plt
from paddlex import create_pipeline
from pathlib import Path
import cv2
import numpy as np
from PIL import Image
import io

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
#plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
#plt.rcParams['axes.unicode_minus'] = False

BASE_DIR = Path(__file__).parent.parent
# ä¸´æ—¶æ³¨é‡Šï¼ˆå¦‚æœæ²¡æœ‰utilsæ¨¡å—ï¼‰ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µä¿ç•™
from utils.app_utils import AppUtils as util
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
plt = util.auto_config_chinese_font()

# å…¨å±€å˜é‡
selected_preset = None


def preprocess_image(image_path):
    """
    å›¾ç‰‡é¢„å¤„ç†ï¼š
    1. æˆªå–ä¸­é—´72%çš„é¢ç§¯ï¼ˆæŒ‰å®½é«˜å„å–ä¸­é—´85%ï¼Œ0.85*0.85â‰ˆ0.72ï¼‰
    2. ç¼©æ”¾è‡³2MBä»¥å†…ï¼Œåˆ†è¾¨ç‡å®½é«˜ä¸è¶…è¿‡1200
    3. ä¿å­˜å›åŸè·¯å¾„è¦†ç›–åŸæ–‡ä»¶
    """
    # è¯»å–å›¾ç‰‡
    try:
        img = cv2.imread(image_path)
        if img is None:
            # å°è¯•ç”¨PILè¯»å–ï¼ˆå…¼å®¹æ›´å¤šæ ¼å¼ï¼‰
            with Image.open(image_path) as pil_img:
                img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

        # è·å–åŸå›¾å°ºå¯¸
        h, w = img.shape[:2]
        print(f"åŸå›¾å°ºå¯¸: {w}x{h}")

        # æ­¥éª¤1ï¼šæˆªå–ä¸­é—´72%é¢ç§¯ï¼ˆå®½é«˜å„å–ä¸­é—´85%ï¼Œ0.85*0.85â‰ˆ0.72ï¼‰
        crop_ratio = 0.85  # å•ç»´åº¦è£å‰ªæ¯”ä¾‹
        # è®¡ç®—è£å‰ªåæ ‡
        x1 = int(w * (1 - crop_ratio) / 2)
        y1 = int(h * (1 - crop_ratio) / 2)
        x2 = int(w - x1)
        y2 = int(h - y1)
        # è£å‰ªå›¾ç‰‡
        cropped_img = img[y1:y2, x1:x2]
        crop_h, crop_w = cropped_img.shape[:2]
        print(f"è£å‰ªåå°ºå¯¸: {crop_w}x{crop_h}")

        # æ­¥éª¤2ï¼šç¼©æ”¾é™åˆ¶ï¼ˆå®½é«˜â‰¤1200ï¼‰
        max_size = 1200
        scale = 1.0
        if crop_w > max_size or crop_h > max_size:
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
            scale = min(max_size / crop_w, max_size / crop_h)
            new_w = int(crop_w * scale)
            new_h = int(crop_h * scale)
            # ç¼©æ”¾å›¾ç‰‡
            cropped_img = cv2.resize(cropped_img, (new_w, new_h), interpolation=cv2.INTER_AREA)


        # æ­¥éª¤3ï¼šæ§åˆ¶æ–‡ä»¶å¤§å°â‰¤2MB
        # å…ˆä¿å­˜åˆ°å†…å­˜ç¼“å†²åŒºï¼Œé€æ­¥è°ƒæ•´è´¨é‡
        encode_params = [cv2.IMWRITE_JPEG_QUALITY, 99]  # é»˜è®¤é«˜è´¨é‡
        ext = os.path.splitext(image_path)[1].lower()

        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©ç¼–ç æ ¼å¼
        if ext in ['.png', '.PNG']:
            encode_params = [cv2.IMWRITE_PNG_COMPRESSION, 6]  # PNGå‹ç¼©çº§åˆ«ï¼ˆ0-9ï¼‰
        elif ext in ['.webp', '.WEBP']:
            encode_params = [cv2.IMWRITE_WEBP_QUALITY, 99]

        # å¾ªç¯è°ƒæ•´ç›´åˆ°æ–‡ä»¶å¤§å°â‰¤2MB
        max_file_size = 2 * 1024 * 1024  # 2MB
        while True:
            # ä¿å­˜åˆ°å†…å­˜
            retval, buffer = cv2.imencode(ext, cropped_img, encode_params)
            file_size = len(buffer)

            if file_size <= max_file_size or encode_params[1] <= 10:
                break

            # é™ä½è´¨é‡/æé«˜å‹ç¼©çº§åˆ«
            if ext in ['.jpg', '.jpeg', '.JPG', '.JPEG', '.webp', '.WEBP']:
                encode_params[1] -= 5  # JPEG/WEBPé™ä½è´¨é‡
            elif ext in ['.png', '.PNG']:
                encode_params[1] += 1  # PNGæé«˜å‹ç¼©çº§åˆ«

        # ä¿å­˜å¤„ç†åçš„å›¾ç‰‡è¦†ç›–åŸæ–‡ä»¶
        with open(image_path, 'wb') as f:
            f.write(buffer)

        file_size_mb = len(buffer) / 1024 / 1024
        print(f"å¤„ç†åæ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB (è´¨é‡/å‹ç¼©çº§åˆ«: {encode_params[1]})")

        return True

    except Exception as e:
        print(f"å›¾ç‰‡é¢„å¤„ç†å¤±è´¥: {str(e)}")
        raise


def process_input(selected_model_dir):
    from paddlex import create_model

    """å¤„ç†å…¨å±€é€‰ä¸­çš„æµ‹è¯•æ–‡ä»¶ï¼Œè¿”å›å›¾è¡¨å’Œç»“æœ"""
    time.sleep(1)
    preset_info = f"æµ‹è¯•æ–‡ä»¶: {selected_preset}" if selected_preset else "æœªé€‰æ‹©æµ‹è¯•æ–‡ä»¶"
    model_info = f"æ¨¡å‹ç›®å½•: {selected_model_dir}"
    result = ''

    # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†æµ‹è¯•æ–‡ä»¶
    if not selected_preset:
        return None, f"é”™è¯¯: è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\n{preset_info}\n{model_info}"
    else:
        # ========== æ–°å¢ï¼šå›¾ç‰‡é¢„å¤„ç† ==========
        try:
            print(f"\nå¼€å§‹é¢„å¤„ç†å›¾ç‰‡: {selected_preset}")
            preprocess_image(selected_preset)
            print("å›¾ç‰‡é¢„å¤„ç†å®Œæˆ")
        except Exception as e:
            return None, f"å›¾ç‰‡é¢„å¤„ç†å¤±è´¥: {str(e)}\n{preset_info}\n{model_info}"

        # ========== åŸæœ‰OCRé€»è¾‘ ==========
        selected_model_dir = selected_model_dir + "/OCR.yaml"
        modeldir = selected_model_dir.replace('\\', '/')
        pipeline = create_pipeline(pipeline=modeldir)

        outdir = f"{BASE_DIR}/output/gangyin_ocr"
        os.makedirs(outdir, exist_ok=True)  # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨

        # æ‰§è¡ŒOCRè¯†åˆ«
        output = pipeline.predict(
            input=selected_preset,
            use_doc_orientation_classify=True,
            use_doc_unwarping=False,
            use_textline_orientation=False,
        )

        # å¤„ç†è¯†åˆ«ç»“æœ
        all_results = []
        for res in output:
            res.print()  ## æ‰“å°é¢„æµ‹çš„ç»“æ„åŒ–è¾“å‡º
            res.save_to_img(save_path=outdir)
            res.save_to_json(save_path=outdir)

            separator = os.sep
            # ä¸ºä¸Šä¼ çš„å›¾ç‰‡ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            json_filename = selected_preset.split(separator)[-1].split('.')[0] + '_res.json'
            img_name = selected_preset.split(separator)[-1].split('.')[0] + '_ocr_res_img.' + \
                       selected_preset.split(separator)[-1].split('.')[1]

            # è¯»å–JSONç»“æœ
            json_path = os.path.join(outdir, json_filename)
            if os.path.exists(json_path):
                with open(json_path, 'r', encoding='utf-8') as file:
                    data = json.load(file)
                    all_results.append(data)

        # æ‹¼æ¥ç»“æœ
        final_img_path = os.path.join(outdir, img_name) if img_name else None
        final_result = json.dumps(all_results, ensure_ascii=False, indent=2) if all_results else "æ— è¯†åˆ«ç»“æœ"

        return final_img_path, final_result


def set_selected(file_path, buttons, file_paths):
    """æ›´æ–°é€‰ä¸­çŠ¶æ€ï¼Œä¿®æ”¹æŒ‰é’®æ ·å¼å¹¶æ›´æ–°å…¨å±€å˜é‡"""
    global selected_preset
    selected_preset = file_path

    # è¿”å›æ‰€æœ‰æŒ‰é’®çš„æ ·å¼æ›´æ–°åˆ—è¡¨
    return [gr.update(variant="primary" if fp == file_path else "secondary") for fp, btn in zip(file_paths, buttons)]


def create_interface():
    # ä»dataset/ç›®å½•åŠ¨æ€è¯»å–CSVæ–‡ä»¶
    cwru_dir = os.path.join(os.path.dirname(__file__), "dataset", "tujiaoji_cls")
    preset_files = {}

    # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–è€…æ­£ç¡®çš„ç›¸å¯¹è·¯å¾„
    if not os.path.exists(cwru_dir):
        # å°è¯•ä½¿ç”¨å…¶ä»–å¯èƒ½çš„è·¯å¾„
        alt_paths = [
            f"{BASE_DIR}/dataset/gangyin_ocr",
            "./dataset/gangyin_ocr",
            "dataset/gangyin_ocr",
        ]
        for path in alt_paths:
            if os.path.exists(path):
                cwru_dir = path
                break

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆç­›é€‰å¸¸è§å›¾ç‰‡æ ¼å¼ï¼‰
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.webp', '.tif']
    if os.path.exists(cwru_dir):
        for file_name in os.listdir(cwru_dir):
            file_ext = os.path.splitext(file_name)[1].lower()
            if file_ext in image_extensions:
                file_path = os.path.join(cwru_dir, file_name)
                preset_files[file_path] = f"ğŸ“„ {file_name}"

    model_dir = os.path.join(os.path.dirname(__file__), "model", "ocr")
    model_options = []  # å°†ä½¿ç”¨å…ƒç»„åˆ—è¡¨: [(å­ç›®å½•åç§°, å®Œæ•´è·¯å¾„)]

    if not os.path.exists(model_dir):
        # å°è¯•ä½¿ç”¨å…¶ä»–å¯èƒ½çš„è·¯å¾„
        alt_model_paths = [
            f"{BASE_DIR}/model/ocr",
            "./model/ocr",
            "model/ocr",
        ]
        for path in alt_model_paths:
            if os.path.exists(path):
                model_dir = path
                break

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰å­ç›®å½•
    if os.path.exists(model_dir):
        for item in os.listdir(model_dir):
            item_path = os.path.join(model_dir, item)
            if os.path.isdir(item_path):
                # æ·»åŠ å…ƒç»„(æ˜¾ç¤ºæ–‡æœ¬, å®é™…å€¼)
                model_options.append((item, item_path))

    with gr.Blocks(title="é’¢å°ocrè¯†åˆ«åº”ç”¨") as demo:
        gr.Markdown("# ğŸš€ é’¢å°ocrè¯†åˆ«åº”ç”¨")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### é€‰æ‹©æµ‹è¯•æ–‡ä»¶")

                # åŠ¨æ€åˆ›å»ºæ–‡ä»¶æŒ‰é’®
                buttons = []
                file_paths = list(preset_files.keys())
                for file_path, display_text in preset_files.items():
                    btn = gr.Button(display_text, variant="secondary", size="lg")
                    buttons.append(btn)

                # åœ¨åˆ›å»ºå®Œæ‰€æœ‰æŒ‰é’®åï¼Œä¸ºæ¯ä¸ªæŒ‰é’®ç»‘å®šç‚¹å‡»äº‹ä»¶
                for i, file_path in enumerate(file_paths):
                    buttons[i].click(
                        fn=lambda path=file_path: set_selected(path, buttons, file_paths),
                        inputs=[],
                        outputs=buttons
                    )

                # æ·»åŠ æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
                gr.Markdown("### é€‰æ‹©æ¨¡å‹")
                model_dropdown = gr.Dropdown(
                    choices=model_options,
                    label="æ¨¡å‹åˆ—è¡¨",
                    value=model_options[0][1] if model_options else ""  # ä½¿ç”¨å…ƒç»„çš„ç¬¬äºŒä¸ªå…ƒç´ ä½œä¸ºé»˜è®¤å€¼
                )

                process_btn = gr.Button("å¤„ç†", variant="primary")

            with gr.Column(scale=2):  # æ‰©å¤§ç»“æœå±•ç¤ºåŒºåŸŸ
                gr.Markdown("### ocræŸ¥çœ‹")
                plot_output = gr.Image(label="è§†å›¾", type="pil", height=400, width=700)

                gr.Markdown("### å¤„ç†ç»“æœ")
                output_text = gr.Textbox(label="é¢„æµ‹ç»“æœ", lines=6)

        # å¤„ç†æŒ‰é’®äº‹ä»¶ï¼ˆè¿”å›å›¾ç‰‡å’Œæ–‡æœ¬ç»“æœï¼‰
        process_btn.click(
            fn=process_input,
            inputs=[model_dropdown],
            outputs=[plot_output, output_text]
        )

    return demo


def main():
    # ä»å‘½ä»¤è¡Œå‚æ•°è·å–ç«¯å£å·ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤ç«¯å£7860
    port = 7861
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            if port < 1024 or port > 65535:
                print(f"è­¦å‘Šï¼šç«¯å£å· {port} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…(1024-65535)ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7860")
                port = 7860
        except ValueError:
            print(f"è­¦å‘Šï¼šæ— æ•ˆçš„ç«¯å£å·å‚æ•° '{sys.argv[1]}'ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7860")

    demo = create_interface()
    demo.launch(allowed_paths=[f'{BASE_DIR}/output'], server_name="0.0.0.0", server_port=port, share=False)


if __name__ == "__main__":
    main()