import datetime
from typing import Tuple

import gradio as gr
import time
import os
import pandas as pd
from paddlex import create_model
import matplotlib.pyplot as plt
from io import BytesIO, StringIO
from PIL import Image
import sys
import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import json
from pathlib import Path

BASE_DIR = Path(__file__).parent.parent
from utils.app_utils import AppUtils as util
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
plt = util.auto_config_chinese_font()
os.makedirs(f'{BASE_DIR}/output/zhoucheng_cls/', exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def generate_bearing_analysis_report(data: dict) -> Tuple[str, str]:
    category_mapping = {
        'ball': 'æ»šåŠ¨ä½“æ•…éšœ',
        'inner': 'å†…åœˆæ•…éšœ',
        'keep': 'ä¿æŒæ¶æ•…éšœ',
        'ok': 'æ­£å¸¸',
        'outer': 'å¤–åœˆæ•…éšœ'
    }
    labels = [category_mapping[key] for key in data.keys()]
    values = [data[key] for key in data.keys()]

    # 2. ç”Ÿæˆä¼˜åŒ–åçš„ç¯å½¢å›¾ï¼ˆè§£å†³æ ‡ç­¾é‡å ï¼‰
    fig, ax = plt.subplots(figsize=(4, 4))
    wedges, texts = ax.pie(
        values,
        wedgeprops=dict(width=0.4),  # ç¯å½¢å®½åº¦
        startangle=90,
        colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']
    )

    # å•ç‹¬åˆ›å»ºå›¾ä¾‹ï¼ˆé¿å…æ ‡ç­¾æŒ¤åœ¨å›¾ä¸Šï¼‰
    ax.legend(
        wedges, labels,
        title="æ•…éšœç±»å‹",
        loc="center left",
        bbox_to_anchor=(1, 0, 0.5, 1)  # å›¾ä¾‹æ”¾åœ¨å›¾å³ä¾§
    )
    # æ‰¾åˆ°æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«å’Œå¯¹åº”æ•°å€¼
    max_value = max(values)
    max_index = values.index(max_value)
    max_label = labels[max_index]

    # åœ¨ç¯å½¢å›¾ä¸­å¿ƒæ˜¾ç¤ºæ¦‚ç‡æœ€å¤§çš„ç±»åˆ«å’Œæ•°å€¼
    ax.text(0, 0, f'{max_label}\næ¦‚ç‡ {max_value:.6f}',
            ha='center', va='center', fontsize=12, fontweight='bold')
    # åœ¨ç¯å½¢å›¾ä¸­å¿ƒæ˜¾ç¤ºä¸»è¦ä¿¡æ¯
    # total_ok = values[labels.index('æ­£å¸¸')]
    # ax.text(0, 0, f'æ­£å¸¸æ¦‚ç‡\n{total_ok:.6f}', ha='center', va='center', fontsize=12, fontweight='bold')

    ax.set_title('è½´æ‰¿æ•…éšœåˆ†æ - é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold', pad=20)
    plt.tight_layout()  # è‡ªåŠ¨è°ƒæ•´å¸ƒå±€

    # ä¿å­˜å›¾ç‰‡
    img_dir = f"{BASE_DIR}/output/zhoucheng_cls/"
    os.makedirs(img_dir, exist_ok=True)
    current_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    img_path = os.path.join(img_dir, f'bearing_analysis_{current_time}.png')
    plt.savefig(img_path, dpi=100, bbox_inches='tight')
    plt.close()

    # 3. å¥åº·çŠ¶æ€è¯„ä¼°
    ok_prob = data['ok']
    fault_probs = [data['ball'], data['inner'], data['keep'], data['outer']]
    max_fault_prob = max(fault_probs)

    if ok_prob == max([ok_prob] + fault_probs):
        status = 'æ­£å¸¸'
        status_icon = 'ğŸŸ¢'
    elif max_fault_prob > 0.8:
        status = 'ä¸¥é‡'
        status_icon = 'ğŸ”´'
    else:
        status = 'é¢„è­¦'
        status_icon = 'ğŸŸ¡'

    # 4. å¥åº·è¯Šæ–­å»ºè®®
    suggestions = []
    if status == 'æ­£å¸¸':
        suggestions = [
            "å½“å‰è½´æ‰¿è¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œå»ºè®®ä¿æŒç°æœ‰çš„è®¾å¤‡å·¡æ£€é¢‘ç‡ï¼Œæ¯å­£åº¦è¿›è¡Œä¸€æ¬¡å¸¸è§„ç»´æŠ¤æ£€æŸ¥ã€‚",
            "å®šæœŸç›‘æµ‹è½´æ‰¿è¿è¡Œæ¸©åº¦å’ŒæŒ¯åŠ¨æ•°æ®ï¼Œå»ºç«‹æ•°æ®æ¡£æ¡ˆï¼Œä¾¿äºåç»­è¶‹åŠ¿åˆ†æã€‚",
            "ç¡®ä¿è½´æ‰¿æ¶¦æ»‘æ¡ä»¶ç¬¦åˆæ ‡å‡†ï¼ŒæŒ‰è®¾å¤‡æ‰‹å†Œè¦æ±‚å®šæœŸæ›´æ¢æ¶¦æ»‘è„‚/æ¶¦æ»‘æ²¹ã€‚"
        ]
    elif status == 'é¢„è­¦':
        fault_type = max(zip(['æ»šåŠ¨ä½“æ•…éšœ', 'å†…åœˆæ•…éšœ', 'ä¿æŒæ¶æ•…éšœ', 'å¤–åœˆæ•…éšœ'], fault_probs), key=lambda x: x[1])[0]
        suggestions = [
            f"æ£€æµ‹åˆ°{fault_type}æ¦‚ç‡å¼‚å¸¸ï¼ˆ{max_fault_prob:.6f}ï¼‰ï¼Œå»ºè®®å¢åŠ å·¡æ£€é¢‘æ¬¡è‡³æ¯å‘¨1-2æ¬¡ï¼Œé‡ç‚¹ç›‘æµ‹è¯¥æ•…éšœç±»å‹ç›¸å…³æŒ‡æ ‡ã€‚",
            "å¯¹è½´æ‰¿è¿›è¡Œå…¨é¢çš„æŒ¯åŠ¨æ£€æµ‹å’Œæ¸©åº¦ç›‘æµ‹ï¼Œåˆ†ææ•…éšœå‘å±•è¶‹åŠ¿ï¼Œè¯„ä¼°å‰©ä½™ä½¿ç”¨å¯¿å‘½ã€‚",
            "æå‰å‡†å¤‡å¤‡ç”¨è½´æ‰¿åŠç›¸å…³æ›´æ¢å·¥å…·ï¼Œåˆ¶å®šåº”æ€¥æ›´æ¢é¢„æ¡ˆï¼Œé˜²æ­¢æ•…éšœçªç„¶æ¶åŒ–ã€‚"
        ]
    else:  # ä¸¥é‡
        fault_type = max(zip(['æ»šåŠ¨ä½“æ•…éšœ', 'å†…åœˆæ•…éšœ', 'ä¿æŒæ¶æ•…éšœ', 'å¤–åœˆæ•…éšœ'], fault_probs), key=lambda x: x[1])[0]
        suggestions = [
            f"{fault_type}æ¦‚ç‡å·²è¶…è¿‡80%ï¼ˆ{max_fault_prob:.6f}ï¼‰ï¼Œè½´æ‰¿å·²å¤„äºé«˜æ•…éšœé£é™©çŠ¶æ€ï¼Œå»ºè®®ç«‹å³åœæœºæ£€æŸ¥å¹¶æ›´æ¢è½´æ‰¿ã€‚",
            "æ›´æ¢å‰éœ€å¯¹è½´æ‰¿åº§ã€è½´é¢ˆç­‰é…åˆéƒ¨ä»¶è¿›è¡Œæ£€æŸ¥ï¼Œç¡®è®¤æ˜¯å¦å­˜åœ¨ç£¨æŸã€å˜å½¢ç­‰è¿å¸¦æŸä¼¤ã€‚",
            "åˆ†ææ•…éšœäº§ç”Ÿçš„æ ¹æœ¬åŸå› ï¼ˆå¦‚æ¶¦æ»‘ä¸è‰¯ã€å®‰è£…åå·®ã€è¿‡è½½è¿è¡Œç­‰ï¼‰ï¼Œé‡‡å–é’ˆå¯¹æ€§æªæ–½é¿å…æ–°è½´æ‰¿é‡å¤å‡ºç°åŒç±»æ•…éšœã€‚"
        ]

    # 5. ç”ŸæˆæŠ¥å‘Šæ­£æ–‡
    analysis_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # æ ¼å¼åŒ–æ¦‚ç‡åˆ†å¸ƒ
    prob_distribution = "\n".join([f"  {label}: {value:.6f}" for label, value in zip(labels, values)])

    report = f"""================================================================================
è½´æ‰¿æ•…éšœåˆ†ææŠ¥å‘Š
================================================================================
åˆ†ææ—¶é—´: {analysis_time}

ã€é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒã€‘
--------------------------------------------------------------------------------
ï¼ˆäº”åˆ†ç±»æ¦‚ç‡å±•ç¤ºï¼‰
{prob_distribution}

ã€å¥åº·çŠ¶æ€è¯„ä¼°ã€‘
--------------------------------------------------------------------------------
  çŠ¶æ€: {status_icon} {status}  
  åˆ¤å®šè§„åˆ™: é¢„è­¦=æ•…éšœæ¦‚ç‡>æ­£å¸¸æ¦‚ç‡ | æ­£å¸¸=æ­£å¸¸æ¦‚ç‡æœ€å¤§ | ä¸¥é‡=æ•…éšœæ¦‚ç‡>0.8


ã€å¥åº·è¯Šæ–­ã€‘
--------------------------------------------------------------------------------
{chr(10).join([f"  {i + 1}. {suggestion}" for i, suggestion in enumerate(suggestions)])}

================================================================================
æŠ¥å‘Šç»“æŸ
================================================================================"""

    return img_path, report

class BearingCNN(nn.Module):
    def __init__(self, input_length, num_classes=5):
        super(BearingCNN, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Conv1d(8, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Conv1d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(2)
        )

        # è®¡ç®—å·ç§¯å±‚è¾“å‡ºå¤§å°
        with torch.no_grad():
            dummy_input = torch.zeros(1, 1, input_length)
            conv_output = self.conv_layers(dummy_input)
            conv_output_size = conv_output.view(1, -1).size(1)

        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(conv_output_size, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x

def load_model_config(load_dir=f"{BASE_DIR}/model/zhoucheng_cls/cnn"):
    """åŠ è½½æ¨¡å‹é…ç½®å’Œæ ‡å‡†åŒ–å‚æ•°"""
    if not os.path.exists(load_dir):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ç›®å½•: {load_dir}")

    # åŠ è½½æ¨¡å‹é…ç½®
    with open(os.path.join(load_dir, "model_config.json"), "r") as f:
        config = json.load(f)

    # åŠ è½½æ ‡å‡†åŒ–å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    scaler = None
    mean_path = os.path.join(load_dir, "mean.npy")
    std_path = os.path.join(load_dir, "std.npy")

    if os.path.exists(mean_path) and os.path.exists(std_path):
        scaler = StandardScaler()
        scaler.mean_ = np.load(mean_path)
        scaler.scale_ = np.load(std_path)

    return config["input_length"], config["num_classes"], scaler

def fft_transform(signals):
    """å¯¹æŒ¯åŠ¨ä¿¡å·è¿›è¡ŒFFTå˜æ¢å¹¶å½’ä¸€åŒ–"""
    fft_results = []

    for signal in signals:
        # è®¡ç®—FFT
        n = len(signal)
        fft_result = np.fft.fft(signal)
        # å–å¹…å€¼å¹¶åªä¿ç•™æ­£é¢‘ç‡éƒ¨åˆ†
        fft_mag = np.abs(fft_result)[:n // 2]

        # å½’ä¸€åŒ–å¤„ç†ï¼šé™¤ä»¥ä¿¡å·é•¿åº¦è¿›è¡Œå¹…åº¦å½’ä¸€åŒ–
        fft_mag = fft_mag / n

        # å¯é€‰ï¼šè¿›ä¸€æ­¥è¿›è¡Œ0-1å½’ä¸€åŒ–ï¼ˆé¿å…é™¤é›¶é”™è¯¯ï¼‰
        max_val = np.max(fft_mag)
        if max_val > 0:
            fft_mag = fft_mag / max_val

        fft_results.append(fft_mag)

    return np.array(fft_results)

def predict_new_data(model, scaler, new_signal, class_names, file_path):
    model.eval()
    try:
        # é‡å¡‘ä¿¡å·ä¸ºäºŒç»´æ•°ç»„ï¼Œé€‚åº”FFTå¤„ç†
        signal = new_signal.reshape(1, -1)

        # è¿›è¡ŒFFTå˜æ¢
        fft_result = fft_transform(signal)

        # ç»˜åˆ¶FFTç»“æœå›¾
        plt.figure(figsize=(10, 4))
        plt.plot(fft_result[0])
        plt.title('FFTé¢‘è°±', fontsize=14)
        plt.xlabel('é¢‘ç‡ç‚¹', fontsize=12)
        plt.yticks([])
        plt.grid(True, which='both', linestyle='--', linewidth=0.5)

        filepath = file_path + '_wave.png'
        filepath = filepath.replace('dataset','output')
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()

        # å¦‚æœæœ‰æ ‡å‡†åŒ–å‚æ•°ï¼Œåˆ™è¿›è¡Œæ ‡å‡†åŒ–
        if scaler is not None:
            fft_result = scaler.transform(fft_result)

        # è½¬æ¢ä¸ºTensorå¹¶æ·»åŠ æ‰¹æ¬¡å’Œé€šé“ç»´åº¦
        input_tensor = torch.tensor(fft_result, dtype=torch.float32).unsqueeze(1).to(device)

        # é¢„æµ‹
        with torch.no_grad():
            output = model(input_tensor)
            probabilities = output.cpu().numpy()[0]

        result_dict = {class_name: float(prob) for class_name, prob in zip(class_names, probabilities)}
        return result_dict

    except Exception as e:
        print(f"é¢„æµ‹å‡ºé”™: {e}")
        return None

def predict_from_csv(model, scaler, class_names, file_path):
    """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®å¹¶é¢„æµ‹"""
    try:
        # è¯»å–æ–‡ä»¶
        df = pd.read_csv(file_path)
        first_column_name = df.columns[0]  # è·å–ç¬¬ä¸€åˆ—çš„åˆ—å
        signal = df[first_column_name].values  # é€šè¿‡åˆ—åè·å–ç¬¬ä¸€åˆ—æ•°æ®
        return predict_new_data(model, scaler, signal, class_names, file_path)
    except Exception as e:
        print(f"ä»CSVæ–‡ä»¶é¢„æµ‹å‡ºé”™: {e}")
        return None

def standalone_prediction(model_path, class_names, file_path):
    """ç‹¬ç«‹çš„é¢„æµ‹å‡½æ•°ï¼Œå¯åœ¨å…¶ä»–è„šæœ¬ä¸­è°ƒç”¨"""

    # åŠ è½½æ¨¡å‹é…ç½®å’Œæ ‡å‡†åŒ–å‚æ•°
    input_length, num_classes, scaler = load_model_config()

    # åŠ è½½æ¨¡å‹
    model = BearingCNN(input_length, num_classes)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)

    # é¢„æµ‹
    result = predict_from_csv(model, scaler, class_names, file_path)
    return result



def plot_time_series(data, title="è¯Šæ–­å›¾"):
    """ç»˜åˆ¶æ—¶åºæ›²çº¿å›¾"""
    plt.figure(figsize=(10, 4))
    # å‡è®¾æ•°æ®åŒ…å«'timestamp'å’Œ'value'åˆ—ï¼Œæ ¹æ®å®é™…æ ¼å¼è°ƒæ•´
    plt.plot(data['Horizontal_vibration_signals'], 'b-', linewidth=2)
    plt.xlabel('æ—¶é—´')
    plt.ylabel('æ•°å€¼')
    plt.title(title)
    plt.xticks(rotation=45)

    # è®¾ç½®yè½´èŒƒå›´ï¼Œç¡®ä¿èƒ½å¤Ÿæ˜¾ç¤ºè´Ÿæ•°
    if 'value' in data.columns:
        min_val = data['value'].min()
        max_val = data['value'].max()
        # æ·»åŠ ä¸€äº›è¾¹è·
        margin = (max_val - min_val) * 0.05
        plt.ylim(min_val - margin, max_val + margin)

    plt.tight_layout()


    # ä¿å­˜åˆ°å†…å­˜
    buf = BytesIO()
    plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')
    buf.seek(0)
    img = Image.open(buf)
    return img


def process_input(selected_model_dir):
    """å¤„ç†å…¨å±€é€‰ä¸­çš„æµ‹è¯•æ–‡ä»¶ï¼Œè¿”å›å›¾è¡¨å’Œç»“æœ"""
    time.sleep(1)
    preset_info = f"æµ‹è¯•æ–‡ä»¶: {selected_preset}" if selected_preset else "æœªé€‰æ‹©æµ‹è¯•æ–‡ä»¶"
    model_info = f"æ¨¡å‹ç›®å½•: {selected_model_dir}"
    class_folders = ["ball", "inner", "keep", "ok", "outer"]

    # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†æµ‹è¯•æ–‡ä»¶
    if not selected_preset:
        return None, f"é”™è¯¯: è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\n{preset_info}\n{model_info}"
    else:
        data = pd.read_csv(selected_preset)
        plot_title = f"å›¾ - {os.path.basename(selected_preset)}"
        plot_img = plot_time_series(data, plot_title)
        rs = standalone_prediction(selected_model_dir + '/bearing_fault_5class_model.pth', class_folders,
                                   selected_preset)
        plot_img,res = generate_bearing_analysis_report(rs)

        return plot_img,res


def set_selected(file_path, buttons, file_paths):
    """æ›´æ–°é€‰ä¸­çŠ¶æ€ï¼Œä¿®æ”¹æŒ‰é’®æ ·å¼å¹¶æ›´æ–°å…¨å±€å˜é‡"""
    global selected_preset
    selected_preset = file_path

    # è¿”å›æ‰€æœ‰æŒ‰é’®çš„æ ·å¼æ›´æ–°åˆ—è¡¨
    # å¯¹äºæ¯ä¸ªæŒ‰é’®ï¼Œå¦‚æœå®ƒå¯¹åº”çš„æ–‡ä»¶è·¯å¾„ä¸é€‰ä¸­çš„æ–‡ä»¶è·¯å¾„ç›¸åŒï¼Œåˆ™è®¾ç½®ä¸ºprimaryï¼ˆé«˜äº®ï¼‰ï¼Œå¦åˆ™è®¾ç½®ä¸ºsecondaryï¼ˆé»˜è®¤ï¼‰
    return [gr.update(variant="primary" if fp == file_path else "secondary") for fp, btn in zip(file_paths, buttons)]


def create_interface():
    #
    cwru_dir = os.path.join(os.path.dirname(__file__), "dataset", "zhoucheng_cls")
    preset_files = {}

    # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–è€…æ­£ç¡®çš„ç›¸å¯¹è·¯å¾„
    if not os.path.exists(cwru_dir):
        # å°è¯•ä½¿ç”¨å…¶ä»–å¯èƒ½çš„è·¯å¾„
        alt_paths = [
            f"{BASE_DIR}/dataset/zhoucheng_cls",
            "./dataset/zhoucheng_cls",
            "dataset/zhoucheng_cls",
        ]
        for path in alt_paths:
            if os.path.exists(path):
                cwru_dir = path
                break

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰CSVæ–‡ä»¶
    if os.path.exists(cwru_dir):
        for file_name in os.listdir(cwru_dir):
            if file_name.endswith('.csv'):
                file_path = os.path.join(cwru_dir, file_name)
                preset_files[file_path] = f"ğŸ“„ {file_name}"

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶

    model_dir = os.path.join(os.path.dirname(__file__), "model", "zhoucheng_cls")
    model_options = []  # å°†ä½¿ç”¨å…ƒç»„åˆ—è¡¨: [(å­ç›®å½•åç§°, å®Œæ•´è·¯å¾„)]

    if not os.path.exists(model_dir):
        # å°è¯•ä½¿ç”¨å…¶ä»–å¯èƒ½çš„è·¯å¾„
        alt_model_paths = [
            f"{BASE_DIR}/model/zhoucheng_cls",
            "./model/zhoucheng_cls",
            "model/zhoucheng_cls",
        ]
        for path in alt_model_paths:
            if os.path.exists(path):
                model_dir = path
                break

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰å­ç›®å½•
    if os.path.exists(model_dir):
        for item in os.listdir(model_dir):
            item_path = os.path.join(model_dir, item)
            if os.path.isdir(item_path):
                # æ·»åŠ å…ƒç»„(æ˜¾ç¤ºæ–‡æœ¬, å®é™…å€¼)
                model_options.append((item, item_path))

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not model_options:
        default_model_name = "Timesnet_cls"
        default_model_dir = os.path.join(model_dir, default_model_name)
        model_options.append((default_model_name, default_model_dir))

    with gr.Blocks(title="è¥¿äº¤-è½´æ‰¿æ•…éšœè¯Šæ–­åº”ç”¨") as demo:
        gr.Markdown("# ğŸš€ è¥¿äº¤-è½´æ‰¿æ•…éšœè¯Šæ–­åº”ç”¨")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### é€‰æ‹©æµ‹è¯•æ–‡ä»¶")

                # åŠ¨æ€åˆ›å»ºæ–‡ä»¶æŒ‰é’®
                buttons = []
                file_paths = list(preset_files.keys())
                for file_path, display_text in preset_files.items():
                    btn = gr.Button(display_text, variant="secondary", size="lg")
                    buttons.append(btn)

                # åœ¨åˆ›å»ºå®Œæ‰€æœ‰æŒ‰é’®åï¼Œä¸ºæ¯ä¸ªæŒ‰é’®ç»‘å®šç‚¹å‡»äº‹ä»¶
                for i, file_path in enumerate(file_paths):
                    buttons[i].click(
                        fn=lambda path=file_path: set_selected(path, buttons, file_paths),
                        inputs=[],
                        outputs=buttons
                    )

                # æ·»åŠ æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
                gr.Markdown("### é€‰æ‹©æ¨¡å‹")
                model_dropdown = gr.Dropdown(
                    choices=model_options,
                    label="æ¨¡å‹åˆ—è¡¨",
                    value=model_options[0][1] if model_options else ""  # ä½¿ç”¨å…ƒç»„çš„ç¬¬äºŒä¸ªå…ƒç´ ä½œä¸ºé»˜è®¤å€¼
                )

                process_btn = gr.Button("å¤„ç†", variant="primary")

            with gr.Column(scale=2):  # æ‰©å¤§ç»“æœå±•ç¤ºåŒºåŸŸ
                gr.Markdown("### å›¾")
                plot_output = gr.Image(label="æ•°æ®å›¾", type="pil")

                gr.Markdown("### å¤„ç†ç»“æœ")
                output_text = gr.Textbox(label="é¢„æµ‹ç»“æœ", lines=6)

        # å¤„ç†æŒ‰é’®äº‹ä»¶ï¼ˆè¿”å›å›¾ç‰‡å’Œæ–‡æœ¬ç»“æœï¼‰
        process_btn.click(
            fn=process_input,
            inputs=[model_dropdown],
            outputs=[plot_output, output_text]
        )

    return demo


def main():
    # ä»å‘½ä»¤è¡Œå‚æ•°è·å–ç«¯å£å·ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤ç«¯å£7860
    port = 7861
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            if port < 1024 or port > 65535:
                print(f"è­¦å‘Šï¼šç«¯å£å· {port} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…(1024-65535)ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7860")
                port = 7860
        except ValueError:
            print(f"è­¦å‘Šï¼šæ— æ•ˆçš„ç«¯å£å·å‚æ•° '{sys.argv[1]}'ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7860")

    demo = create_interface()
    demo.launch(allowed_paths=[f'{BASE_DIR}/output'],server_name="0.0.0.0", server_port=port, share=False)


if __name__ == "__main__":
    main()