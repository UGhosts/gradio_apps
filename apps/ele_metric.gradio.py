import gradio as gr
import paddlex as pdx
import os,sys
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import json

# --- å…¨å±€OCRå®ä¾‹ ---
ocr_instance = None

# --- æ¨¡å‹ç›®å½•é…ç½® ---
MODEL_BASE_DIR = "/home/software/gradio_apps/model/ele_metric_ocr"

def generate_paddlex_model_options(base_dir: str) -> dict:
    """
    åŠ¨æ€æ‰«ææŒ‡å®šç›®å½•ï¼Œè‡ªåŠ¨ç”ŸæˆPaddleXçš„æ¨¡å‹é…ç½®å­—å…¸ã€‚
    æ”¯æŒï¼š
      - å®Œæ•´è‡ªå®šä¹‰æ¨¡å‹ï¼ˆdet + recï¼‰
      - ä»…è‡ªå®šä¹‰æ£€æµ‹æ¨¡å‹ + é»˜è®¤è¯†åˆ«æ¨¡å‹
      - PaddleXé¢„è®­ç»ƒæ¨¡å‹
    """
    if not os.path.isdir(base_dir):
        print(f"è­¦å‘Š: æ¨¡å‹æ ¹ç›®å½• '{base_dir}' ä¸å­˜åœ¨ã€‚å°†è¿”å›ç©ºé…ç½®ã€‚")
        return {}
    
    # model_collection = {"display_name":MODEL_BASE_DIR.split('/')[-1]}
    model_collection = {}
    

    for file in os.listdir(base_dir):
        if file.endswith('.yaml'):
            model_name = file.split('.')[0]
            model_collection[model_name] = os.path.join(base_dir, file)
    
    return model_collection

# åŠ¨æ€ç”Ÿæˆæ¨¡å‹é€‰é¡¹
MODEL_OPTIONS = generate_paddlex_model_options(MODEL_BASE_DIR)

EXAMPLE_IMAGES_DIR = "/home/software/gradio_apps/dataset/ele_metric_ocr"
EXAMPLE_IMAGES = []

def load_example_images():
    """åŠ è½½ç¤ºä¾‹å›¾ç‰‡åˆ—è¡¨"""
    global EXAMPLE_IMAGES
    EXAMPLE_IMAGES = []
    if os.path.exists(EXAMPLE_IMAGES_DIR):
        for filename in sorted(os.listdir(EXAMPLE_IMAGES_DIR)):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                EXAMPLE_IMAGES.append(os.path.join(EXAMPLE_IMAGES_DIR, filename))

# åˆå§‹åŠ è½½
load_example_images()

# --- é‡å¯ä¿¡å·å’Œæ–‡ä»¶ç›‘æ§å¤„ç† ---
RESTART_SIGNAL_FILE = ".restart_signal"

def trigger_restart():
    """åˆ›å»ºé‡å¯ä¿¡å·æ–‡ä»¶å¹¶ç»ˆæ­¢å½“å‰åº”ç”¨è¿›ç¨‹ã€‚"""
    print("æ£€æµ‹åˆ°æ–‡ä»¶å˜åŒ–ï¼Œæ­£åœ¨è§¦å‘åº”ç”¨é‡å¯...")
    with open(RESTART_SIGNAL_FILE, "w") as f:
        f.write("restart")
    
    monitor_manager.stop_all(join_threads=False)
    print("åº”ç”¨è¿›ç¨‹å³å°†é€€å‡º...")
    os._exit(0)

class DirectoryHandler(FileSystemEventHandler):
    def __init__(self):
        super().__init__()
    
    def on_created(self, event):
        trigger_restart()
    
    def on_deleted(self, event):
        trigger_restart()
    
    def on_moved(self, event):
        trigger_restart()

class MultiDirectoryMonitor:
    """ä¸€ä¸ªå¯ä»¥ç®¡ç†å¤šä¸ªç›®å½•ç›‘æ§ä»»åŠ¡çš„ç±»ã€‚"""
    def __init__(self):
        self._directories_to_watch = set()
        self._observers = []

    def add_directory(self, path: str):
        """æ³¨å†Œä¸€ä¸ªéœ€è¦è¢«ç›‘æ§çš„ç›®å½•è·¯å¾„ã€‚"""
        if os.path.abspath(path) not in self._directories_to_watch:
            self._directories_to_watch.add(os.path.abspath(path))
            print(f"ç›®å½•å·²æ³¨å†Œç›‘æ§: {path}")

    def start_all(self):
        """ä¸ºæ‰€æœ‰å·²æ³¨å†Œçš„ç›®å½•å¯åŠ¨ç›‘æ§ã€‚"""
        if self._observers:
            print("ç›‘æ§å·²ç»åœ¨è¿è¡Œä¸­ã€‚")
            return

        handler = DirectoryHandler()
        for path in self._directories_to_watch:
            os.makedirs(path, exist_ok=True)
            observer = Observer()
            observer.schedule(handler, path, recursive=True)
            self._observers.append(observer)
        
        for observer in self._observers:
            observer.start()
            
        print(f"âœ… å·²å¯åŠ¨å¯¹ {len(self._observers)} ä¸ªç›®å½•çš„ç›‘æ§ã€‚")

    def stop_all(self, join_threads: bool = True):
        """åœæ­¢æ‰€æœ‰ç›‘æ§ä»»åŠ¡ã€‚"""
        for observer in self._observers:
            if observer.is_alive():
                observer.stop()

        if join_threads:
            for observer in self._observers:
                observer.join()
        
        self._observers = []
        print("âœ… æ‰€æœ‰ç›‘æ§ä»»åŠ¡å·²åœæ­¢ã€‚")

# åˆ›å»ºå…¨å±€ç®¡ç†å™¨å®ä¾‹
monitor_manager = MultiDirectoryMonitor()

def get_current_examples():
    """è·å–å½“å‰ç¤ºä¾‹å›¾ç‰‡åˆ—è¡¨ï¼ˆæ ¼å¼åŒ–ä¸ºGalleryéœ€è¦çš„æ ¼å¼ï¼‰"""
    examples = []
    if EXAMPLE_IMAGES:
        for example_path in EXAMPLE_IMAGES:
            examples.append([example_path, ""])
    return examples

def initialize_ocr(model_choice):
    """æ ¹æ®ç”¨æˆ·é€‰æ‹©åˆå§‹åŒ–PaddleX OCRæ¨¡å‹"""
    global ocr_instance
    try:
        models_config = MODEL_OPTIONS[model_choice]
        ocr_instance = pdx.create_pipeline(models_config)
        
    except Exception as e:
        error_msg = f"âœ— åˆå§‹åŒ–æ¨¡å‹å¤±è´¥: {str(e)}"
        return error_msg


MAX_OCR_IMAGE_SIZE = 1280 

def resize_image_for_ocr(image, max_long_side=MAX_OCR_IMAGE_SIZE):
    """
    å°†å›¾ç‰‡ç­‰æ¯”ä¾‹ç¼©æ”¾åˆ°é€‚åˆOCRå¤„ç†çš„å°ºå¯¸ã€‚
    """
    h, w = image.shape[:2] if len(image.shape) >= 2 else (0, 0)
    
    if h == 0 or w == 0:
        return image, 1.0

    # å¦‚æœå›¾ç‰‡å°ºå¯¸å·²ç»å°äºç­‰äºé˜ˆå€¼ï¼Œåˆ™æ— éœ€å¤„ç†
    if h <= max_long_side and w <= max_long_side:
        return image, 1.0

    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    if h > w:
        ratio = max_long_side / h
        new_h = max_long_side
        new_w = int(w * ratio)
    else:
        ratio = max_long_side / w
        new_w = max_long_side
        new_h = int(h * ratio)
        
    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    
    return resized_image, ratio

def draw_ocr_results(image_path, model_choice):
    global ocr_instance
    
    if not os.path.exists(image_path):
        return None, "é”™è¯¯: å›¾ç‰‡æœªæ‰¾åˆ°ã€‚"

    # å¦‚æœOCRå®ä¾‹ä¸å­˜åœ¨æˆ–æ¨¡å‹å‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°åˆå§‹åŒ–
    if ocr_instance is None:
        initialize_ocr(model_choice)

    try:
        # ä½¿ç”¨ OpenCV è¯»å–åŸå§‹å›¾åƒ
        original_image = cv2.imread(image_path)
        if original_image is None:
            return None, "é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶ã€‚"
        processed_image, scale_ratio = resize_image_for_ocr(original_image)
        print(f"å›¾ç‰‡å°ºå¯¸å·²ä» {original_image.shape[:2]} é¢„å¤„ç†ä¸º {processed_image.shape[:2]}ï¼Œç¼©æ”¾æ¯”ä¾‹: {scale_ratio:.4f}")
        # æ‰§è¡ŒOCRè¯†åˆ« - å…¼å®¹ä¸åŒçš„æ–¹æ³•
        if hasattr(ocr_instance, 'predict'):
            # ä½¿ç”¨æ‚¨åŸæ¥çš„predictæ–¹æ³•
            result = ocr_instance.predict(processed_image)
        else:
            # ä½¿ç”¨æ ‡å‡†çš„ocræ–¹æ³•
            result = ocr_instance.ocr(processed_image, cls=True)
        
        try:
            # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
            font = ImageFont.truetype("/usr/share/fonts/truetype/wqy/wqy-microhei.ttc", 25)
        except IOError:
            try:
                # å¤‡é€‰å­—ä½“
                font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 25)
            except IOError:
                font = ImageFont.load_default()
        
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
        
        # å¤„ç†ä¸åŒæ ¼å¼çš„ç»“æœ
        result = list(result) 
        if result and len(result) > 0:
            # æ£€æŸ¥æ˜¯å¦æ˜¯åŸæ¥çš„predictæ–¹æ³•è¿”å›çš„æ ¼å¼
            if isinstance(result[0], dict) and 'rec_texts' in result[0]:
                # ä½¿ç”¨åŸæ¥çš„å¤„ç†é€»è¾‘
                page_result = result[0]
                rec_texts = page_result.get('rec_texts', [])
                rec_scores = page_result.get('rec_scores', [])
                rec_polys = page_result.get('rec_polys', [])
                
                # åŒæ­¥ç­›é€‰ï¼Œåªä¿ç•™ rec_texts é•¿åº¦ > 4 çš„é¡¹
                filtered_data = [
                    (text, score, poly) 
                    for text, score, poly in zip(rec_texts, rec_scores, rec_polys) 
                    if len(text) > 3 and (len(text) < 7 or '.' in text)
                ]

                # ç¬¬äºŒæ­¥ï¼šå¦‚æœç»“æœè¶…è¿‡2ä¸ªï¼Œè¿›ä¸€æ­¥ç­›é€‰ä»¥0å¼€å¤´çš„
                if len(filtered_data) > 2:
                    zero_start_data = [(text, score, poly) for text, score, poly in filtered_data if text.startswith('0')]
                    if zero_start_data:
                        filtered_data = zero_start_data

                # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœä»æœ‰å¤šä¸ªç»“æœï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
                if len(filtered_data) > 1:
                    filtered_data = [filtered_data[0]]
                
                # è§£åŒ…å›å„è‡ªçš„åˆ—è¡¨
                rec_texts, rec_scores, rec_polys = zip(*filtered_data) if filtered_data else ([], [], [])
                
                output_img = page_result['doc_preprocessor_res'].get('output_img')
                if len(output_img.shape) == 3 and output_img.shape[2] == 3:
                    # å‡è®¾æ˜¯BGRæ ¼å¼ï¼Œè½¬æ¢ä¸ºRGB
                    output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(output_img)
                draw = ImageDraw.Draw(pil_image)
                
                if not (rec_texts and rec_scores and rec_polys):
                    return np.array(pil_image), "æœªè¯†åˆ«åˆ°æ–‡æœ¬"
                
                recognition_count = 0
                for idx in range(len(rec_texts)):
                    text = rec_texts[idx].strip().lstrip('0')
                    confidence = rec_scores[idx]
                    points = rec_polys[idx]
                    
                    # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
                    if not text or confidence < 0.5:
                        continue
                    
                    recognition_count += 1
                    color = colors[idx % len(colors)]
                    text_label = f'{text}   å¯ä¿¡åº¦: {confidence:.1%}'
                    
                    # ç»˜åˆ¶è¾¹æ¡†
                    draw.polygon([tuple(p) for p in points], outline=color, width=3)
                    
                    # ç»˜åˆ¶æ–‡æœ¬æ ‡ç­¾
                    text_position = (int(points[0][0]), max(0, int(points[0][1]) - 30))
                    padding = 5
                    
                    try:
                        # è®¡ç®—æ–‡æœ¬èƒŒæ™¯æ¡†
                        text_bbox = draw.textbbox(text_position, text_label, font=font)
                        padded_bbox = [
                            text_bbox[0] - padding,
                            text_bbox[1] - padding,
                            text_bbox[2] + padding,
                            text_bbox[3] + padding
                        ]
                        draw.rectangle(padded_bbox, fill=(2, 166, 13))
                    except Exception as e:
                        # ç®€å•èƒŒæ™¯æ¡†
                        text_width = len(text_label) * 12
                        text_height = 25
                        simple_bbox = [
                            text_position[0] - padding,
                            text_position[1] - padding,
                            text_position[0] + text_width + padding,
                            text_position[1] + text_height + padding
                        ]
                        draw.rectangle(simple_bbox, fill=(166, 43, 90))
                    
                    # ç»˜åˆ¶æ–‡æœ¬
                    draw.text(text_position, text_label, fill=(255, 255, 255), font=font)
                    
            else:
                # æ ‡å‡†OCRç»“æœæ ¼å¼å¤„ç†
                # è½¬æ¢ä¸ºRGBæ ¼å¼çš„PILå›¾åƒ
                pil_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
                draw = ImageDraw.Draw(pil_image)
                
                recognition_count = 0
                for idx, line in enumerate(result[0] if result[0] else []):
                    if len(line) >= 2:
                        points = np.array(line[0], dtype=np.int32)
                        text = line[1][0] if isinstance(line[1], tuple) else str(line[1])
                        confidence = line[1][1] if isinstance(line[1], tuple) and len(line[1]) > 1 else 1.0
                        
                        # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
                        if confidence < 0.5 or not text.strip():
                            continue
                        
                        recognition_count += 1
                        color = colors[idx % len(colors)]
                        text_label = f'{text}  [{confidence:.1%}]'
                        
                        # ç»˜åˆ¶è¾¹æ¡†
                        draw.polygon([tuple(p) for p in points], outline=color, width=2)
                        
                        # ç»˜åˆ¶æ–‡æœ¬æ ‡ç­¾
                        text_position = (int(points[0][0]), max(0, int(points[0][1]) - 25))
                        
                        # è®¡ç®—æ–‡æœ¬èƒŒæ™¯æ¡†
                        try:
                            bbox = draw.textbbox(text_position, text_label, font=font)
                            padding = 3
                            bg_bbox = [bbox[0]-padding, bbox[1]-padding, bbox[2]+padding, bbox[3]+padding]
                            draw.rectangle(bg_bbox, fill=(0, 0, 0, 180))
                        except:
                            # ç®€å•èƒŒæ™¯æ¡†
                            text_width = len(text_label) * 10
                            bg_bbox = [text_position[0]-3, text_position[1]-3, 
                                     text_position[0]+text_width+3, text_position[1]+20]
                            draw.rectangle(bg_bbox, fill=(0, 0, 0))
                        
                        # ç»˜åˆ¶æ–‡æœ¬
                        draw.text(text_position, text_label, fill=(255, 255, 255), font=font)
            
            status_msg = f"{text_label}" if recognition_count > 0 else "æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬"
        else:
            # å¦‚æœæ²¡æœ‰è¯†åˆ«ç»“æœï¼Œè¿”å›åŸå§‹å›¾åƒ
            pil_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
            status_msg = "æœªæ£€æµ‹åˆ°æ–‡æœ¬"
        
        result_image = np.array(pil_image)
        return result_image, status_msg
            
    except Exception as e:
        print(f"OCR å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        try:
            # è¿”å›åŸå§‹å›¾åƒå’Œé”™è¯¯ä¿¡æ¯
            image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
            return image, f"OCR å¤„ç†å‡ºé”™: {str(e)}"
        except:
            return None, f"OCR å¤„ç†å‡ºé”™: {str(e)}"

def ocr_image(image_path, model_choice):
    """ä¸»å¤„ç†å‡½æ•°"""
    if image_path is None:
        return None, "è¯·å…ˆä¸Šä¼ æˆ–é€‰æ‹©å›¾ç‰‡"
    return draw_ocr_results(image_path, model_choice)

def load_example(example_path):
    """åŠ è½½ç¤ºä¾‹å›¾ç‰‡"""
    return example_path

def clear_outputs():
    """æ¸…ç©ºæ‰€æœ‰è¾“å‡º"""
    return None, None, ""

def change_model(model_choice):
    """åˆ‡æ¢æ¨¡å‹æ—¶çš„å›è°ƒ"""
    global ocr_instance
    ocr_instance = None  # é‡ç½®OCRå®ä¾‹ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
    return f"å·²é€‰æ‹©æ¨¡å‹: {model_choice}ï¼Œä¸‹æ¬¡è¯†åˆ«æ—¶å°†è‡ªåŠ¨åŠ è½½"

def refresh_examples():
    """æ‰‹åŠ¨åˆ·æ–°ç¤ºä¾‹å›¾ç‰‡åˆ—è¡¨"""
    load_example_images()
    examples = get_current_examples()
    status_msg = f"å·²åˆ·æ–°ï¼Œæ‰¾åˆ° {len(EXAMPLE_IMAGES)} å¼ ç¤ºä¾‹å›¾ç‰‡"
    if not examples:
        status_msg = "*æ²¡æœ‰æ‰¾åˆ°ç¤ºä¾‹å›¾ç‰‡ï¼Œè¯·åœ¨ ./examples/ ç›®å½•ä¸‹æ·»åŠ å›¾ç‰‡æ–‡ä»¶*"
    return examples, status_msg

# health check
health_check_js = '''
() => {
    let isConnected = true;
    setInterval(async () => {
        try {
            await fetch('/app_id');
            if (!isConnected) {
                console.log("æˆåŠŸé‡æ–°è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ­£åœ¨åˆ·æ–°é¡µé¢...");
                location.reload();
            }
            isConnected = true;
        } catch (e) {
            if (isConnected) {
                console.log("ä¸æœåŠ¡å™¨çš„è¿æ¥å·²æ–­å¼€ï¼Œç­‰å¾…é‡æ–°è¿æ¥...");
            }
            isConnected = false;
        }
    }, 2000);
}
'''

# --- åˆ›å»º Gradio ç•Œé¢ ---
with gr.Blocks(title="PaddleX æ™ºèƒ½æ–‡å­—è¯†åˆ«", theme=gr.themes.Default(), js=health_check_js) as iface:
    gr.Markdown("""
    # ğŸ” ç”µè¡¨è¯»æ•°OCR
    **åŠŸèƒ½ç‰¹ç‚¹ï¼š** åŸºäºPaddleXæ¡†æ¶çš„OCRè¯†åˆ«ã€æ”¯æŒå¤šç§æ¨¡å‹é€‰æ‹©ã€æä¾›ç¤ºä¾‹å›¾ç‰‡ã€å®æ—¶å¯è§†åŒ–è¯†åˆ«ç»“æœ
    """)
    
    with gr.Row():
        # å·¦ä¾§ï¼šç¤ºä¾‹å›¾ç‰‡å’Œæ¨¡å‹é€‰æ‹©
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ–¼ï¸ ç¤ºä¾‹å›¾ç‰‡")
            with gr.Row():
                gr.Markdown("ç‚¹å‡»ä¸‹æ–¹ç¤ºä¾‹å›¾ç‰‡å¿«é€Ÿä½“éªŒè¯†åˆ«æ•ˆæœï¼š")
            
            initial_examples = get_current_examples()

            example_gallery = gr.Gallery(
                value=initial_examples,
                label="ç‚¹å‡»é€‰æ‹©ç¤ºä¾‹",
                show_label=False,
                elem_id="example_gallery",
                columns=4,
                rows=1,
                height=200,
                allow_preview=False
            )
                
            gr.Markdown("### ğŸ¤– æ¨¡å‹é€‰æ‹©")
            model_selector = gr.Dropdown(
                choices=list(MODEL_OPTIONS.keys()),
                value=list(MODEL_OPTIONS.keys())[0] if MODEL_OPTIONS else None,
                label="é€‰æ‹©OCRæ¨¡å‹",
                info="æ”¯æŒPaddleXé¢„è®­ç»ƒæ¨¡å‹å’Œè‡ªå®šä¹‰æ¨¡å‹"
            )

            with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=True):
                gr.Markdown("""
                **æ“ä½œæ­¥éª¤ï¼š**
                1. é€‰æ‹©åˆé€‚çš„OCRæ¨¡å‹
                2. ä¸Šä¼ å›¾ç‰‡æˆ–é€‰æ‹©ç¤ºä¾‹å›¾ç‰‡
                3. ç‚¹å‡»"å¼€å§‹è¯†åˆ«"æŒ‰é’®
                4. æŸ¥çœ‹è¯†åˆ«ç»“æœå’Œå¯è§†åŒ–æ ‡æ³¨
                
                **æ”¯æŒæ ¼å¼ï¼š** JPG, PNG, JPEG

                **åŸºäºæ¡†æ¶ï¼š** PaddleX
                """)
            
        # å³ä¾§ï¼šä¸Šä¼ å’Œç»“æœ
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“¤ ä¸Šä¼ å›¾ç‰‡")
            input_image = gr.Image(
                type="filepath", 
                label="ä¸Šä¼ å›¾ç‰‡",
                height=200,
                sources=['upload']
            )
            
            with gr.Row():
                submit_btn = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")
            
            gr.Markdown("### ğŸ“‹ è¯†åˆ«ç»“æœ")
            output_image = gr.Image(label="è¯†åˆ«ç»“æœå¯è§†åŒ–", height=600)
            result_status = gr.Textbox(label="è¯†åˆ«ç»“æœ", interactive=False)

    # äº‹ä»¶ç»‘å®š
    def select_example(evt: gr.SelectData):
        current_examples = get_current_examples()
        if current_examples and evt.index < len(current_examples):
            selected_path = current_examples[evt.index][0]
            return selected_path
        return None

    example_gallery.select(select_example, None, outputs=[input_image])
    
    submit_btn.click(
        fn=ocr_image,
        inputs=[input_image, model_selector],
        outputs=[output_image, result_status]
    )
    
    clear_btn.click(
        fn=clear_outputs,
        outputs=[input_image, output_image, result_status]
    )
    
    model_selector.change(
        fn=change_model,
        inputs=[model_selector]
    )

def main():
    # ç¡®ä¿ç¤ºä¾‹ç›®å½•å­˜åœ¨
    os.makedirs(EXAMPLE_IMAGES_DIR, exist_ok=True)
    
    # å¯åŠ¨ç›®å½•ç›‘æ§
    monitor_manager.add_directory(EXAMPLE_IMAGES_DIR)
    monitor_manager.add_directory(MODEL_BASE_DIR)
    monitor_manager.start_all()
    
    port = 7861
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            if port < 1024 or port > 65535:
                print(f"è­¦å‘Šï¼šç«¯å£å· {port} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…(1024-65535)ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7861")
                port = 7861
        except ValueError:
            print(f"è­¦å‘Šï¼šæ— æ•ˆçš„ç«¯å£å·å‚æ•° '{sys.argv[1]}'ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£7861")
    
    try:
        iface.launch(
            server_name="0.0.0.0",
            server_port=port,
            share=False,
        )
    finally:
        # åº”ç”¨å…³é—­æ—¶åœæ­¢ç›‘æ§
        monitor_manager.stop_all(join_threads=True)
    
    
# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    main()
    
