import gradio as gr
import paddlex as pdx
import os,sys
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import json
from utils.app_utils import AppUtils as util
from utils.app_utils import MultiDirectoryMonitor
from pathlib import Path
# --- å…¨å±€OCRå®ä¾‹ ---
ocr_instance = None

from pathlib import Path

# --- æ¨¡å‹ç›®å½•é…ç½® ---
BASE_DIR = Path(__file__).parent.parent
MODEL_BASE_DIR = BASE_DIR / "model" / "ele_metric_ocr" / "model"
RESTART_SIGNAL_FILENAME = ".restart_signal_ele_metric"
EXAMPLE_DIR = BASE_DIR / "model" / "ele_metric_ocr" / "example"


model_options = util.generate_paddlex_model_options(MODEL_BASE_DIR)


# --- é‡å¯ä¿¡å·å’Œæ–‡ä»¶ç›‘æ§å¤„ç† ---


def initialize_ocr(model_choice):
    """æ ¹æ®ç”¨æˆ·é€‰æ‹©åˆå§‹åŒ–PaddleX OCRæ¨¡å‹"""
    global ocr_instance
    try:
        print(model_options)
        models_config = model_options[model_choice]
        
        # ç¬¬ä¸€æ¬¡å°è¯•åˆå§‹åŒ–ï¼ˆå¦‚æœå¤±è´¥ä¼šç›´æ¥è¿›å…¥exceptï¼‰
        ocr_instance = pdx.create_pipeline(models_config)
        return "âœ“ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ"
        
    except Exception as first_error:
        # å¦‚æœç¬¬ä¸€æ¬¡åˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ä»é…ç½®æ–‡ä»¶çš„åŒçº§ç›®å½•åŠ è½½.yamlæ–‡ä»¶
        try:
            current_path = Path(models_config).parent.parent / "pipeline"
            yaml_files = [file for file in current_path.iterdir() if file.suffix == ".yaml"]
            
            if not yaml_files:
                raise Exception("æœªæ‰¾åˆ°å¯ç”¨çš„.yamlé…ç½®æ–‡ä»¶")
                
            # å°è¯•åŠ è½½ç¬¬ä¸€ä¸ª.yamlæ–‡ä»¶ï¼ˆå¦‚æœå¤±è´¥ä¼šæŠ›å‡ºå¼‚å¸¸ï¼‰
            ocr_instance = pdx.create_pipeline(str(yaml_files[0]))  # ç¡®ä¿ä¼ å…¥å­—ç¬¦ä¸²è·¯å¾„
            return "âœ“ ä»å¤‡ç”¨.yamlæ–‡ä»¶åˆå§‹åŒ–æˆåŠŸ"
            
        except Exception as fallback_error:
            print(
                f"âœ— åˆå§‹åŒ–æ¨¡å‹å¤±è´¥:\n"
                f"- ä¸»é…ç½®å¤±è´¥: {str(first_error)}\n"
                f"- å¤‡ç”¨.yamlæ–‡ä»¶å¤±è´¥: {str(fallback_error)}"
            )
            return None


MAX_OCR_IMAGE_SIZE = 1280 

def resize_image_for_ocr(image, max_long_side=MAX_OCR_IMAGE_SIZE):
    """
    å°†å›¾ç‰‡ç­‰æ¯”ä¾‹ç¼©æ”¾åˆ°é€‚åˆOCRå¤„ç†çš„å°ºå¯¸ã€‚
    """
    h, w = image.shape[:2] if len(image.shape) >= 2 else (0, 0)
    
    if h == 0 or w == 0:
        return image, 1.0

    # å¦‚æœå›¾ç‰‡å°ºå¯¸å·²ç»å°äºç­‰äºé˜ˆå€¼ï¼Œåˆ™æ— éœ€å¤„ç†
    if h <= max_long_side and w <= max_long_side:
        return image, 1.0

    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    if h > w:
        ratio = max_long_side / h
        new_h = max_long_side
        new_w = int(w * ratio)
    else:
        ratio = max_long_side / w
        new_w = max_long_side
        new_h = int(h * ratio)
        
    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    
    return resized_image, ratio

def draw_ocr_results(image_path, model_choice):
    global ocr_instance
    
    if not os.path.exists(image_path):
        return None, "é”™è¯¯: å›¾ç‰‡æœªæ‰¾åˆ°ã€‚"

    # å¦‚æœOCRå®ä¾‹ä¸å­˜åœ¨æˆ–æ¨¡å‹å‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°åˆå§‹åŒ–
    if ocr_instance is None:
        initialize_ocr(model_choice)

    try:
        # ä½¿ç”¨ OpenCV è¯»å–åŸå§‹å›¾åƒ
        original_image = cv2.imread(image_path)
        if original_image is None:
            return None, "é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶ã€‚"
        processed_image, scale_ratio = resize_image_for_ocr(original_image)
        print(f"å›¾ç‰‡å°ºå¯¸å·²ä» {original_image.shape[:2]} é¢„å¤„ç†ä¸º {processed_image.shape[:2]}ï¼Œç¼©æ”¾æ¯”ä¾‹: {scale_ratio:.4f}")
        # æ‰§è¡ŒOCRè¯†åˆ« - å…¼å®¹ä¸åŒçš„æ–¹æ³•
        if hasattr(ocr_instance, 'predict'):
            # ä½¿ç”¨æ‚¨åŸæ¥çš„predictæ–¹æ³•
            result = ocr_instance.predict(processed_image)
        else:
            # ä½¿ç”¨æ ‡å‡†çš„ocræ–¹æ³•
            result = ocr_instance.ocr(processed_image, cls=True)
        
        try:
            # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
            font = ImageFont.truetype("/usr/share/fonts/truetype/wqy/wqy-microhei.ttc", 25)
        except IOError:
            try:
                # å¤‡é€‰å­—ä½“
                font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 25)
            except IOError:
                font = ImageFont.load_default()
        
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
        
        # å¤„ç†ä¸åŒæ ¼å¼çš„ç»“æœ
        result = list(result) 
        if result and len(result) > 0:
            # æ£€æŸ¥æ˜¯å¦æ˜¯åŸæ¥çš„predictæ–¹æ³•è¿”å›çš„æ ¼å¼
            if isinstance(result[0], dict) and 'rec_texts' in result[0]:
                # ä½¿ç”¨åŸæ¥çš„å¤„ç†é€»è¾‘
                page_result = result[0]
                rec_texts = page_result.get('rec_texts', [])
                rec_scores = page_result.get('rec_scores', [])
                rec_polys = page_result.get('rec_polys', [])
                
                # åŒæ­¥ç­›é€‰ï¼Œåªä¿ç•™ rec_texts é•¿åº¦ > 4 çš„é¡¹
                filtered_data = [
                    (text, score, poly) 
                    for text, score, poly in zip(rec_texts, rec_scores, rec_polys) 
                    if len(text) > 3 and (len(text) < 7 or '.' in text)
                ]

                # ç¬¬äºŒæ­¥ï¼šå¦‚æœç»“æœè¶…è¿‡2ä¸ªï¼Œè¿›ä¸€æ­¥ç­›é€‰ä»¥0å¼€å¤´çš„
                if len(filtered_data) > 2:
                    zero_start_data = [(text, score, poly) for text, score, poly in filtered_data if text.startswith('0')]
                    if zero_start_data:
                        filtered_data = zero_start_data

                # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœä»æœ‰å¤šä¸ªç»“æœï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
                if len(filtered_data) > 1:
                    filtered_data = [filtered_data[0]]
                
                # è§£åŒ…å›å„è‡ªçš„åˆ—è¡¨
                rec_texts, rec_scores, rec_polys = zip(*filtered_data) if filtered_data else ([], [], [])
                
                output_img = page_result['doc_preprocessor_res'].get('output_img')
                if len(output_img.shape) == 3 and output_img.shape[2] == 3:
                    # å‡è®¾æ˜¯BGRæ ¼å¼ï¼Œè½¬æ¢ä¸ºRGB
                    output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(output_img)
                draw = ImageDraw.Draw(pil_image)
                
                if not (rec_texts and rec_scores and rec_polys):
                    return np.array(pil_image), "æœªè¯†åˆ«åˆ°æ–‡æœ¬"
                
                recognition_count = 0
                for idx in range(len(rec_texts)):
                    text = rec_texts[idx].strip().lstrip('0')
                    confidence = rec_scores[idx]
                    points = rec_polys[idx]
                    
                    # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
                    if not text or confidence < 0.5:
                        continue
                    
                    recognition_count += 1
                    color = colors[idx % len(colors)]
                    text_label = f'{text}   å¯ä¿¡åº¦: {confidence:.1%}'
                    
                    # ç»˜åˆ¶è¾¹æ¡†
                    draw.polygon([tuple(p) for p in points], outline=color, width=3)
                    
                    # ç»˜åˆ¶æ–‡æœ¬æ ‡ç­¾
                    text_position = (int(points[0][0]), max(0, int(points[0][1]) - 30))
                    padding = 5
                    
                    try:
                        # è®¡ç®—æ–‡æœ¬èƒŒæ™¯æ¡†
                        text_bbox = draw.textbbox(text_position, text_label, font=font)
                        padded_bbox = [
                            text_bbox[0] - padding,
                            text_bbox[1] - padding,
                            text_bbox[2] + padding,
                            text_bbox[3] + padding
                        ]
                        draw.rectangle(padded_bbox, fill=(2, 166, 13))
                    except Exception as e:
                        # ç®€å•èƒŒæ™¯æ¡†
                        text_width = len(text_label) * 12
                        text_height = 25
                        simple_bbox = [
                            text_position[0] - padding,
                            text_position[1] - padding,
                            text_position[0] + text_width + padding,
                            text_position[1] + text_height + padding
                        ]
                        draw.rectangle(simple_bbox, fill=(166, 43, 90))
                    
                    # ç»˜åˆ¶æ–‡æœ¬
                    draw.text(text_position, text_label, fill=(255, 255, 255), font=font)
                    
            else:
                # æ ‡å‡†OCRç»“æœæ ¼å¼å¤„ç†
                # è½¬æ¢ä¸ºRGBæ ¼å¼çš„PILå›¾åƒ
                pil_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
                draw = ImageDraw.Draw(pil_image)
                
                recognition_count = 0
                for idx, line in enumerate(result[0] if result[0] else []):
                    if len(line) >= 2:
                        points = np.array(line[0], dtype=np.int32)
                        text = line[1][0] if isinstance(line[1], tuple) else str(line[1])
                        confidence = line[1][1] if isinstance(line[1], tuple) and len(line[1]) > 1 else 1.0
                        
                        # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
                        if confidence < 0.5 or not text.strip():
                            continue
                        
                        recognition_count += 1
                        color = colors[idx % len(colors)]
                        text_label = f'{text}  [{confidence:.1%}]'
                        
                        # ç»˜åˆ¶è¾¹æ¡†
                        draw.polygon([tuple(p) for p in points], outline=color, width=2)
                        
                        # ç»˜åˆ¶æ–‡æœ¬æ ‡ç­¾
                        text_position = (int(points[0][0]), max(0, int(points[0][1]) - 25))
                        
                        # è®¡ç®—æ–‡æœ¬èƒŒæ™¯æ¡†
                        try:
                            bbox = draw.textbbox(text_position, text_label, font=font)
                            padding = 3
                            bg_bbox = [bbox[0]-padding, bbox[1]-padding, bbox[2]+padding, bbox[3]+padding]
                            draw.rectangle(bg_bbox, fill=(0, 0, 0, 180))
                        except:
                            # ç®€å•èƒŒæ™¯æ¡†
                            text_width = len(text_label) * 10
                            bg_bbox = [text_position[0]-3, text_position[1]-3, 
                                     text_position[0]+text_width+3, text_position[1]+20]
                            draw.rectangle(bg_bbox, fill=(0, 0, 0))
                        
                        # ç»˜åˆ¶æ–‡æœ¬
                        draw.text(text_position, text_label, fill=(255, 255, 255), font=font)
            
            status_msg = f"{text_label}" if recognition_count > 0 else "æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬"
        else:
            # å¦‚æœæ²¡æœ‰è¯†åˆ«ç»“æœï¼Œè¿”å›åŸå§‹å›¾åƒ
            pil_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
            status_msg = "æœªæ£€æµ‹åˆ°æ–‡æœ¬"
        
        result_image = np.array(pil_image)
        return result_image, status_msg
            
    except Exception as e:
        print(f"OCR å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        try:
            # è¿”å›åŸå§‹å›¾åƒå’Œé”™è¯¯ä¿¡æ¯
            image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
            return image, f"OCR å¤„ç†å‡ºé”™: {str(e)}"
        except:
            return None, f"OCR å¤„ç†å‡ºé”™: {str(e)}"

def ocr_image(image_path, model_choice):
    """ä¸»å¤„ç†å‡½æ•°"""
    if image_path is None:
        return None, "è¯·å…ˆä¸Šä¼ æˆ–é€‰æ‹©å›¾ç‰‡"
    return draw_ocr_results(image_path, model_choice)

def load_example(example_path):
    """åŠ è½½ç¤ºä¾‹å›¾ç‰‡"""
    return example_path

def clear_outputs():
    """æ¸…ç©ºæ‰€æœ‰è¾“å‡º"""
    return None, None, ""

def change_model(model_choice):
    """åˆ‡æ¢æ¨¡å‹æ—¶çš„å›è°ƒ"""
    global ocr_instance
    ocr_instance = None  # é‡ç½®OCRå®ä¾‹ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
    return f"å·²é€‰æ‹©æ¨¡å‹: {model_choice}ï¼Œä¸‹æ¬¡è¯†åˆ«æ—¶å°†è‡ªåŠ¨åŠ è½½"

def refresh_examples():
    """æ‰‹åŠ¨åˆ·æ–°ç¤ºä¾‹å›¾ç‰‡åˆ—è¡¨"""
    load_example_images()
    examples = get_current_examples()
    status_msg = f"å·²åˆ·æ–°ï¼Œæ‰¾åˆ° {len(EXAMPLE_IMAGES)} å¼ ç¤ºä¾‹å›¾ç‰‡"
    if not examples:
        status_msg = "*æ²¡æœ‰æ‰¾åˆ°ç¤ºä¾‹å›¾ç‰‡ï¼Œè¯·åœ¨ ./examples/ ç›®å½•ä¸‹æ·»åŠ å›¾ç‰‡æ–‡ä»¶*"
    return examples, status_msg

def create_gradio_interface():
    health_check_js = '''
    () => {
        let isConnected = true;
        setInterval(async () => {
            try {
                await fetch('/');
                if (!isConnected) {
                    console.log("æˆåŠŸé‡æ–°è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ­£åœ¨åˆ·æ–°é¡µé¢...");
                    location.reload();
                }
                isConnected = true;
            } catch (e) {
                if (isConnected) {
                    console.log("ä¸æœåŠ¡å™¨çš„è¿æ¥å·²æ–­å¼€ï¼Œç­‰å¾…é‡æ–°è¿æ¥...");
                }
                isConnected = false;
            }
        }, 2000);
    }
    '''

    # --- åˆ›å»º Gradio ç•Œé¢ ---
    with gr.Blocks(title="PaddleX æ™ºèƒ½æ–‡å­—è¯†åˆ«", theme=gr.themes.Default(), js=health_check_js) as iface:
        gr.Markdown("""
        # ğŸ” ç”µè¡¨è¯»æ•°OCR
        **åŠŸèƒ½ç‰¹ç‚¹ï¼š** åŸºäºPaddleXæ¡†æ¶çš„OCRè¯†åˆ«ã€æ”¯æŒå¤šç§æ¨¡å‹é€‰æ‹©ã€æä¾›ç¤ºä¾‹å›¾ç‰‡ã€å®æ—¶å¯è§†åŒ–è¯†åˆ«ç»“æœ
        """)
        
        with gr.Row():
            # å·¦ä¾§ï¼šç¤ºä¾‹å›¾ç‰‡å’Œæ¨¡å‹é€‰æ‹©
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ–¼ï¸ ç¤ºä¾‹å›¾ç‰‡")
                with gr.Row():
                    gr.Markdown("ç‚¹å‡»ä¸‹æ–¹ç¤ºä¾‹å›¾ç‰‡å¿«é€Ÿä½“éªŒè¯†åˆ«æ•ˆæœï¼š")
                

                example_gallery = gr.Gallery(
                    value=util.get_current_examples(EXAMPLE_DIR),
                    label="ç‚¹å‡»é€‰æ‹©ç¤ºä¾‹",
                    show_label=False,
                    elem_id="example_gallery",
                    columns=4,
                    rows=1,
                    height=200,
                    allow_preview=False
                )
                    
                gr.Markdown("### ğŸ¤– æ¨¡å‹é€‰æ‹©")
                model_selector = gr.Dropdown(
                        choices=list(model_options.keys()),
                        value=list(model_options.keys())[0] if model_options else None,
                    label="é€‰æ‹©OCRæ¨¡å‹",
                    info="æ”¯æŒPaddleXé¢„è®­ç»ƒæ¨¡å‹å’Œè‡ªå®šä¹‰æ¨¡å‹"
                )

                with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=True):
                    gr.Markdown("""
                    **æ“ä½œæ­¥éª¤ï¼š**
                    1. é€‰æ‹©åˆé€‚çš„OCRæ¨¡å‹
                    2. ä¸Šä¼ å›¾ç‰‡æˆ–é€‰æ‹©ç¤ºä¾‹å›¾ç‰‡
                    3. ç‚¹å‡»"å¼€å§‹è¯†åˆ«"æŒ‰é’®
                    4. æŸ¥çœ‹è¯†åˆ«ç»“æœå’Œå¯è§†åŒ–æ ‡æ³¨
                    
                    **æ”¯æŒæ ¼å¼ï¼š** JPG, PNG, JPEG
                    
                    **åŸºäºæ¡†æ¶ï¼š** PaddleX
                    """)
                
            # å³ä¾§ï¼šä¸Šä¼ å’Œç»“æœ
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ ä¸Šä¼ å›¾ç‰‡")
                input_image = gr.Image(
                    type="filepath", 
                    label="ä¸Šä¼ å›¾ç‰‡",
                    height=200,
                    sources=['upload']
                )
                
                with gr.Row():
                    submit_btn = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")
                
                gr.Markdown("### ğŸ“‹ è¯†åˆ«ç»“æœ")
                output_image = gr.Image(label="è¯†åˆ«ç»“æœå¯è§†åŒ–", height=600)
                result_status = gr.Textbox(label="è¯†åˆ«ç»“æœ", interactive=False)

        # äº‹ä»¶ç»‘å®š
        def select_example(evt: gr.SelectData):
            current_examples = util.get_current_examples(EXAMPLE_DIR)
            if current_examples and evt.index < len(current_examples):
                selected_path = current_examples[evt.index]
                return selected_path
            return None

        example_gallery.select(select_example, None, outputs=[input_image])
        
        submit_btn.click(
            fn=ocr_image,
            inputs=[input_image, model_selector],
            outputs=[output_image, result_status]
        )
        
        clear_btn.click(
            fn=clear_outputs,
            outputs=[input_image, output_image, result_status]
        )
        
        model_selector.change(
            fn=change_model,
            inputs=[model_selector]
        )
        return iface
def main():
    monitor_manager = MultiDirectoryMonitor(restart_signal_file_name=RESTART_SIGNAL_FILENAME)
    monitor_manager.add_directory(MODEL_BASE_DIR)
    monitor_manager.add_directory(EXAMPLE_DIR)
    if not monitor_manager.start_all():
        print("âŒ å¯åŠ¨ç›®å½•ç›‘æ§å¤±è´¥")
        return
    port = 7861
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            if port < 1024 or port > 65535:
                print(f"è­¦å‘Šï¼šç«¯å£å· {port} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…(1024-65535)ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£{port}")
                port = port
        except ValueError:
            print(f"è­¦å‘Šï¼šæ— æ•ˆçš„ç«¯å£å·å‚æ•° '{sys.argv[1]}'ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«¯å£{port}")
    iface = create_gradio_interface()
    try:
        iface.launch(
            server_name="0.0.0.0",
            server_port=port,
            share=False,
        )
    finally:
        # åº”ç”¨å…³é—­æ—¶åœæ­¢ç›‘æ§
        monitor_manager.stop_all(join_threads=True)
    
    
# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    main()
    
